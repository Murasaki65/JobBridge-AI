{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11424740,"sourceType":"datasetVersion","datasetId":7155164},{"sourceId":11431894,"sourceType":"datasetVersion","datasetId":7160041}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 🔍 Introduction\n---\n**JobBridge-AI** is a research-driven UX and AI Capstone project developed as part of the *Gen AI Intensive Course*.<br>\nIt tackles real-world challenges faced by foreigners seeking employment in Japan — challenges I personally experienced while navigating the Japanese job market.<br>\n\nMotivated by those experiences, I built JobBridge-AI to explore user pain points and design smarter, more supportive tools.<br>\nBy leveraging **Generative AI** technologies like Google Gemini, LangChain, and LangGraph, the system delivers personalized résumé feedback, UX advice, and culturally-aware career suggestions based on user questions and uploaded CVs.","metadata":{}},{"cell_type":"markdown","source":"# 🗻 Why Japan\n---\nJapan is a unique job market with strong local hiring customs, a high emphasis on language ability, and limited resources tailored to non-Japanese speakers.<br>\nFor many foreigners from students and new graduates to mid-career professionals —  \nthe job search process can feel confusing and isolating.<br>\n\nMany job seekers face barriers including language proficiency (N2/N1), lack of sponsorship, and mismatch with recruiter expectations.<br>\nThey struggle to navigate Japanese job platforms, understand resume formats (like 履歴書 and 職務経歴書), or prepare for bilingual interviews that blend keigo and technical Q&A.<br>\n\nWhile Japan offers exciting career opportunities for global talent, the path is not always clear.<br>\nLanguage barriers, unfamiliar application standards, and cultural differences can leave even highly qualified candidates feeling lost or overlooked.<br>\n\nWith a growing number of international students and foreign professionals entering Japan each year, there's an urgent need for smarter, more inclusive support systems.<br>  \n**JobBridge-AI** was created to help bridge that gap by combining generative AI with UX insights focused on real-world job search struggles.<br>","metadata":{}},{"cell_type":"markdown","source":"# 🎯 Project Goals\n---\nThe goal of JobBridge-AI is to empower foreign job seekers in Japan with smarter, more empathetic support during the job-hunting process.\n\n### 🎯 Key Objectives:\n- 🔍 **Identify** common frustrations in the Japanese job market through real UX research\n- 🧠 **Leverage Generative AI** to offer resume rewrites, career suggestions, and feedback\n- 🌐 **Bridge the language gap** with bilingual AI outputs and simplified UX\n- 🤖 **Build a working chatbot prototype** using LangGraph, LangChain, and Gemini","metadata":{}},{"cell_type":"markdown","source":"# 👕 Target Audience\n---\nTarget Group for This Project\nThis project focuses on foreign residents in Japan who face unique challenges in the job search process.<br>\nBased on our research goals, we identified the following key user segments:\n\n- **International Students & Language School Learners**<br>\nOften on student visas, these users are actively job hunting while balancing Japanese language classes. Many aim to transition into full-time roles in tech, hospitality, or creative fields.\n\n- **English Teachers Seeking Career Change**<br>\nMany participants reported being \"stuck\" in ALT or eikaiwa roles, despite having skills or experience in other industries. They often struggle to move out of education due to hiring bias and unclear career pathways.\n\n- **Highly Skilled Visa Holders or Employees**<br>\nThis group includes engineers, designers, or professionals on work or spouse visas. Despite strong credentials, many are overlooked due to language level, visa type, or cultural mismatch in hiring expectations.\n\nTo ensure diverse and inclusive insights, we aim to conduct UX research across these groups,<br>\ncovering a broad range of Japanese proficiency levels (N5 to N1) and multiple industries, including tech, hospitality, education, and creative sectors.","metadata":{}},{"cell_type":"markdown","source":"# 🧠 Gather User Insights\n---\nTo understand the challenges faced by foreign job seekers in Japan, we planned a mixed-method UX study targeting over 100 foreign professionals across multiple industries.<br>\nThe research included both a bilingual UX survey and in-depth interviews, conducted in English and Japanese.\n\nDespite time constraints, we successfully collected responses from **30+ foreign participants** via survey and conducted **10 individual interviews**.<br>\nThese insights became foundational to our AI training, grounding its advice in real-world frustrations.\n\n\n### 📋 1. Bilingual Survey (Google Form)\nA bilingual survey (English/Japanese) was distributed to foreign job seekers in Japan.  \nThe survey explored themes such as language proficiency, visa challenges, recruiter experiences, and job search pain points.\n\n**Top 5 reported pain points:**\n1. 🧱 **Language barrier** (especially N2+ requirement)\n2. ⚔️ **Competition with local candidates**\n3. 🔍 **Difficulty identifying suitable jobs** \n4. 🤝 **Limited networking opportunities**\n5. 🌐 **Cultural differences in interviews**\n\n**Status**: ✅ Survey completed (30+ respondents)  \n**Insights Summary**:  \nThere’s a clear demand for tools that decode job descriptions, tailor resumes, and support bilingual candidates more effectively.\n\n\n### 🗣️ 2. Individual Interviews (Google Meet)\nIn-depth interviews were conducted in English and Japanese to explore pain points in greater depth.  \nOriginally, 20+ interviews were planned, but we successfully completed 10 within the project timeline.\n\nThese sessions captured rich personal experiences and validated many of the survey's trends.\n\n**Key insights:**\n- Conflicting or vague recruiter feedback is common.\n- Several reported unethical hiring practices (e.g., unpaid “test” tasks).\n- Networking and insider referrals are seen as essential — yet inaccessible for most foreigners.\n\n**Status**: ✅ Interview sampling completed (10 participants)  \n**Insights Summary**:  \nThe job hunt is not only about language or formatting. It’s also about **clarity, trust, and fairness**.<br>\nThis underscores the need for tools that are not only smart — but also **empathetic** and culturally aware.\n\n\nData from both the survey and interviews was compiled into a bilingual JSON dataset (`ux_survey.json`)<br> and integrated into the RAG pipeline via:<br>\nux_insights → job_advice_seeds → job_advice_node","metadata":{}},{"cell_type":"markdown","source":"# 🧑‍🎨 User Personas\nPersona Media link [job-bridge-media](https://www.kaggle.com/datasets/nattaveelaws/job-bridge-media/)\n\n---\n\n## **Figure:** Persona #1 – Aya Suwanisan<br>\nAge: 22<br>\nVISA Type: Student Visa<br>\nCurrent Status: Studying Japanese language, Working part-time at an izakaya<br>\nLanguage: Japanese N3 (Intermediate), English Fluent<br>\nTarget Roles: Full-time hospitality<br><br>\n### “It feels like no one will even look at your profile if you’re not fluent  even if the job says 'English OK'.”<br>\n### Goals \n- To land her first full-time job in a restaurant that values work ethic and training, not just JLPT scores\n- To build confidence interacting with Japanese customers and co-workers\n- To transition from part-time back-of-house staff to a customer-facing or managerial role\n\n### Frustrations\n- Job posts advertise “English OK,” but interviews are conducted entirely in Japanese\n- She’s unsure what to emphasize in a Japanese-style resume or 自己PR\n- Feels discouraged when she’s ghosted after interviews or told she’s “not fluent enough”\n\nAya, 26, is a Thai student in Osaka studying Japanese while working part-time at an izakaya.<br>\nShe hopes to land a full-time role in Japan’s food service industry, but finds “English OK” job posts misleading and her N3 Japanese seen as insufficient.<br>\nShe’s eager to grow, but struggles with unclear entry paths into stable hospitality roles.\n\n---\n\n## **Figure:** Persona #2 – Daniel Thompson<br>\n### Daniel Thompson\nAge: 31<br>\nVISA Type: Work Visa<br>\nCurrent Status: Full-time English teacher in a public elementary school<br>\nLanguage: Japanese N2 (Fluent), English Native<br>\nTarget Roles: Content Creation / Creative Tech<br><br>\n### “Once you become a teacher in Japan, they can’t see you as anything else even if your resume says content creator.”<br>\n\n### Goals \n- To pivot from teaching to a full-time role in content or creative tech\n- To use his Japanese fluency and media background to create meaningful cross-cultural content\n- To build a career path beyond ALT work and grow into leadership in a creative environment\n  \n### Frustrations\n- ALT experience overshadows his previous media work. Recruiters don’t read past the first line\n- Job posts claim “English OK” but interviews are entirely in Japanese and high-context\n- Lack of clear criteria portfolios are ignored unless hosted on Japanese platforms\n### Persona Summarize\nDaniel is a New Zealand media professional working as an ALT in Tokyo.<br>\nWith a background in scriptwriting and fluent Japanese (N2), he came to Japan to pursue a career in creative content.<br>\nBut visa routes pushed him into teaching. Now three years in,<br>\nhe’s rebuilding his portfolio in Japanese and looking for companies that value cross-cultural creativity not just teaching experience.\n\n---\n## **Figure:** Persona #3 – Amira Elbaz<br>\n### Amira Elbaz\nAge: 39<br>\nVISA Type: Dependent Visa (Spouse of Permanent Resident)<br>\nCurrent Status: Freelancing remotely applying to tech roles<br>\nLanguage: Japanese N4, English Fluent<br>\nTarget Roles: Backend Developer / QA / Infrastructure<br><br>\n### “My experience is solid but no one sees it because I’m on a spouse visa and speak only N4.”<br>\n### Goals \n- To re-enter the tech industry in Japan after moving for family\n- To use her 10+ years of backend development experience\n- To join a diverse team that values real experience over paperwork\n\n### Frustrations\n- Gets filtered out for not having N2, even for roles labeled “English OK”\n- Recruiters focus on her visa instead of her résumé\n- Job boards push her toward teaching or retail, ignoring her skillset\n### Persona Summarize\nAmira is a seasoned backend engineer from Egypt, now living in Saitama on a spouse visa.<br>\nDespite 10+ years of experience, her limited Japanese and visa status often lead recruiters to overlook her.<br>\nShe’s now refining her GitHub and resume in Japanese, aiming to join a tech team that values skills over status.\n\n","metadata":{}},{"cell_type":"markdown","source":"# 🛤️ User Journeys\n---\n1. User uploads a resume PDF.\n2. The system parses it into structured fields (name, education, experience...).\n3. The user can ask the bot to:\n   - Rewrite the resume for a specific company\n   - Get job advice based on their situation\n   - Ask for alternative roles\n4. The assistant responds using:\n   - Few-shot prompts (for CV)\n   - RAG (for advice)\n   - LLM generation (for jobs)","metadata":{}},{"cell_type":"markdown","source":"# 🚀 Features Implemented\n---\nJobBridge-AI integrates multiple generative AI capabilities to support the user journey, from CV preparation to career advice.<br>\nEach feature is designed to address specific pain points identified through UX research and interviews.<br><br>\n\n| 🧩 Feature | 🧠 Capability | 🔧 Method |\n|-----------|---------------|-----------|\n| **CV Parsing** | Resume document understanding | Gemini LLM + PDF parsing pipeline |\n| **Rewrite 自己PR & 志望動機** | Few-shot + controlled generation | Prompt-based rewrite using user-uploaded CVs |\n| **UX-Driven Advice** | Retrieval-Augmented Generation (RAG) | Embedding search over user pain points (vector DB) |\n| **Recommend Alternative Jobs** | Career guidance from similar profiles | Custom retriever using ChromaDB + Gemini |\n| **Conversational Agent** | Chatbot interface with smart routing | LangGraph-based flow control and input intent detection |","metadata":{}},{"cell_type":"markdown","source":"# 🧰 Capabilities Demonstrated\n---\nThis project demonstrates multiple GenAI capabilities as required by the Kaggle x Google Capstone Challenge.<br>\nEach technique was integrated intentionally to solve a user-validated pain point.\n\n| Capability | Description | Example in Project |\n|------------|-------------|--------------------|\n| **Document Understanding** | Reads and extracts content from uploaded résumés (PDF) | CV parsing via Gemini |\n| **Few-shot Prompting** | Controlled rewriting of 自己PR and 志望動機 | Uses examples to generate company-tailored versions |\n| **Retrieval-Augmented Generation (RAG)** | Embeds and retrieves pain point data for contextual UX advice | Embedding + ChromaDB |\n| **Dynamic Routing via LangGraph** | Multi-node chatbot routing based on user intent | LangGraph nodes: parse, tailor, ux_advice, alt_jobs |\n| **Multilingual Input/Output** | Accepts and generates both English and Japanese content | All core features are bilingual |","metadata":{}},{"cell_type":"markdown","source":"# 🎨 UX Accessibility Considerations\n---\n**JobBridge-AI** was designed with empathy for real users navigating the Japanese job market — many of whom face barriers related to language, culture, and unfamiliar application systems.  \nOur design was grounded in insights from bilingual UX surveys and user interviews.\n\n---\n\n### 🧩 Accessibility Features\n- **Multilingual Support:** Accepts both English and Japanese inputs, with bilingual outputs.\n- **Automatic Resume Parsing:** Users can upload a résumé PDF without formatting knowledge — the system parses and extracts content automatically.\n- **Low Barrier to Entry:** No need for prior familiarity with Japanese resume formats like 履歴書 or 職務経歴書.\n\n---\n\n### 🫂 Inclusive Design Principles\n- Supports users across all JLPT levels (N5 to N1)\n- Accepts open-ended queries (e.g., “fix my PR” or “what job suits me?”)\n- Transparent interactions: each AI step (e.g., tailoring, advice generation) is printed with clear system labels — no \"black box\" behavior.\n\n---\n\n### ⚠️ Known Limitations\n- ❌ No support for audio input or OCR (camera-captured image CVs) at this time\n- ❌ Mobile usability is constrained due to the Kaggle Notebook interface\n- ❌ Does not yet handle handwritten resumes (手書き履歴書), which some companies still request in Japan\n","metadata":{}},{"cell_type":"markdown","source":"# 🧪 Usability Testing\n---\n### Planned Flow (Originally Intended)\n1. Build a working prototype using Gemini 2 Flash to analyze user CVs.  \n2. Invite users to test and provide feedback on language clarity, output relevance, and overall usefulness.  \n3. Collect qualitative feedback via a short follow-up form or interview.  \n4. Iterate based on input and re-test improved versions.\n\n---\n\n### 🛠 Tools (Prepared)\n- **Kaggle Notebook**: Used as the user-facing interface for rapid prototyping.  \n- **Gemini API**: Powers CV understanding, RAG, and resume rewriting logic.  \n\n---\n\n### ❌ Status: Testing Not Completed  \nDue to time limitations during the Capstone Challenge window, we were unable to run formal usability testing sessions.  \nOur team prioritized core system functionality, integration, and UX-driven logic design.\n\n---\n\n### ⚠️ Known Gaps\n- No structured user feedback has been collected yet.  \n- Improvement areas remain speculative, based on survey expectations rather than real session logs or usage data.\n\n---\n\n**Next steps (post-capstone):**  \nWe plan to conduct lightweight usability testing with foreign job seekers currently in Japan to validate and refine prompt flows, language accessibility, and overall interaction clarity.","metadata":{}},{"cell_type":"markdown","source":"# Let's start\nIn this sample, we will use the uploaded resume of Daniel Thompson, one of our personas.  \nMedia link [job-bridge-media](https://www.kaggle.com/datasets/nattaveelaws/job-bridge-media/)","metadata":{}},{"cell_type":"markdown","source":"# [1] Library Installation & Environment Setup\n---\nInstalls the core libraries required for this project, including Gemini, LangGraph, LangChain, and ChromaDB.  \nPDF parsing is handled via `PyPDF2`.  \nAll dependencies are pinned to ensure compatibility within the Kaggle environment.","metadata":{}},{"cell_type":"code","source":"# clean up any pre‑installed copies\n!pip uninstall -qqy google-generativeai google-ai-generativelanguage\n\n# system OCR package\n# !apt-get -qq update && apt-get -qq install -y tesseract-ocr\n\n# Python libs  ── note the explicit 0.8.4 / 0.6.15 pair, and upgrade langgraph\n!pip install -U \\\n    google-generativeai==0.8.4 \\\n    google-ai-generativelanguage==0.6.15 \\\n    langgraph==0.3.30 \\\n    langchain langchain-community langchain-google-genai \\\n    chromadb PyPDF2 pandas\n\nprint(\"✅ Libraries installed (including langgraph>=0.3.30)\")\nprint(\"✅ Libraries installed (0.8.4 / 0.6.15 pair)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:23:13.771694Z","iopub.execute_input":"2025-04-19T15:23:13.772029Z","iopub.status.idle":"2025-04-19T15:24:08.763465Z","shell.execute_reply.started":"2025-04-19T15:23:13.772005Z","shell.execute_reply":"2025-04-19T15:24:08.762432Z"}},"outputs":[{"name":"stdout","text":"Collecting google-generativeai==0.8.4\n  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\nCollecting google-ai-generativelanguage==0.6.15\n  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\nCollecting langgraph==0.3.30\n  Downloading langgraph-0.3.30-py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\nCollecting langchain\n  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\nCollecting langchain-community\n  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\nCollecting langchain-google-genai\n  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\nCollecting chromadb\n  Downloading chromadb-1.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nCollecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.4) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.4) (2.160.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.4) (2.27.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.4) (3.20.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.4) (2.11.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.4) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.4) (4.13.1)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15) (1.26.0)\nRequirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.3.30) (0.3.35)\nCollecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph==0.3.30)\n  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\nCollecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph==0.3.30)\n  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\nCollecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph==0.3.30)\n  Downloading langgraph_sdk-0.1.61-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.3.30) (3.5.0)\nCollecting langchain-core<0.4,>=0.1 (from langgraph==0.3.30)\n  Downloading langchain_core-0.3.54-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.16)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nCollecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nINFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-google-genai\n  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\nCollecting build>=1.0.3 (from chromadb)\n  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\nCollecting chroma-hnswlib==0.7.6 (from chromadb)\n  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nCollecting fastapi==0.115.9 (from chromadb)\n  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\nCollecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\nCollecting posthog>=2.4.0 (from chromadb)\n  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\nCollecting onnxruntime>=1.14.1 (from chromadb)\n  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\nCollecting pypika>=0.48.9 (from chromadb)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\nCollecting bcrypt>=4.0.1 (from chromadb)\n  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\nCollecting kubernetes>=28.1.0 (from chromadb)\n  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\nCollecting mmh3>=4.0.1 (from chromadb)\n  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\nRequirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (14.0.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\nCollecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\nRequirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\nCollecting pyproject_hooks (from build>=1.0.3->chromadb)\n  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai==0.8.4) (1.67.0)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (1.48.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.4) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.4) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.4) (4.9)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.22.3)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\nRequirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\nCollecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph==0.3.30) (1.33)\nCollecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph==0.3.30)\n  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2.4.1)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\nRequirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.1.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\nINFO: pip is looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.0-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-exporter-otlp-proto-common==1.32.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.32.0-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-proto==1.32.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.32.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-exporter-otlp-proto-common==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-proto==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.31.1-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.31.1-py3-none-any.whl.metadata (1.6 kB)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\nCollecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\nCollecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-exporter-otlp-proto-common==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\nINFO: pip is still looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-exporter-otlp-proto-common==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.28.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\nCollecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\nCollecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\nINFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.53b0-py3-none-any.whl.metadata (2.2 kB)\nCollecting opentelemetry-instrumentation-asgi==0.53b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.53b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.53b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.53b0-py3-none-any.whl.metadata (6.8 kB)\nCollecting opentelemetry-semantic-conventions==0.53b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.53b0-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-util-http==0.53b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.53b0-py3-none-any.whl.metadata (2.6 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.32.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\nCollecting opentelemetry-instrumentation-asgi==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\nCollecting opentelemetry-semantic-conventions==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-util-http==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.52b1-py3-none-any.whl.metadata (2.6 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.31.1-py3-none-any.whl.metadata (1.6 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl.metadata (2.2 kB)\nCollecting opentelemetry-instrumentation-asgi==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl.metadata (6.8 kB)\nCollecting opentelemetry-semantic-conventions==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-util-http==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl.metadata (2.6 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.31.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\nCollecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\nCollecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\nCollecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\nCollecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation-asgi==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl.metadata (2.0 kB)\nCollecting opentelemetry-instrumentation==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\nCollecting opentelemetry-semantic-conventions==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-util-http==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.49b1-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\nINFO: pip is still looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.49b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation-asgi==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.49b0-py3-none-any.whl.metadata (2.0 kB)\nCollecting opentelemetry-instrumentation==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\nCollecting opentelemetry-semantic-conventions==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-util-http==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.49b0-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.28.0-py3-none-any.whl.metadata (1.4 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\nCollecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\nCollecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\nCollecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\nCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nCollecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai==0.8.4) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai==0.8.4) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai==0.8.4) (0.4.0)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.30.2)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai==0.8.4) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai==0.8.4) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai==0.8.4) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai==0.8.4) (3.2.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\nRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph==0.3.30) (3.0.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.8.4) (0.6.1)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.2->langchain-community) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nDownloading google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langgraph-0.3.30-py3-none-any.whl (144 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chromadb-1.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\nDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\nDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.54-py3-none-any.whl (433 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\nDownloading langgraph_checkpoint-2.0.24-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\nDownloading langgraph_sdk-0.1.61-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\nDownloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\nDownloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\nDownloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\nDownloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\nDownloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading durationpy-0.9-py3-none-any.whl (3.5 kB)\nDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\nDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\nDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53800 sha256=79de5c8991fee99977517c5d33b44f71c51a4a4f5d21cc0747bad48943bad8b9\n  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\nSuccessfully built pypika\nInstalling collected packages: pypika, monotonic, filetype, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, PyPDF2, ormsgpack, opentelemetry-util-http, opentelemetry-proto, mmh3, importlib-metadata, humanfriendly, httpx-sse, httptools, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, pydantic-settings, opentelemetry-semantic-conventions, opentelemetry-instrumentation, langgraph-sdk, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation-asgi, langchain-core, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langgraph-checkpoint, langchain-text-splitters, google-ai-generativelanguage, langgraph-prebuilt, langchain, google-generativeai, langgraph, langchain-google-genai, onnxruntime, chroma-hnswlib, langchain-community, chromadb\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib_metadata 8.6.1\n    Uninstalling importlib_metadata-8.6.1:\n      Successfully uninstalled importlib_metadata-8.6.1\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.16.0\n    Uninstalling opentelemetry-api-1.16.0:\n      Successfully uninstalled opentelemetry-api-1.16.0\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.16.0\n    Uninstalling opentelemetry-sdk-1.16.0:\n      Successfully uninstalled opentelemetry-sdk-1.16.0\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.35\n    Uninstalling langchain-core-0.3.35:\n      Successfully uninstalled langchain-core-0.3.35\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.6\n    Uninstalling langchain-text-splitters-0.3.6:\n      Successfully uninstalled langchain-text-splitters-0.3.6\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.18\n    Uninstalling langchain-0.3.18:\n      Successfully uninstalled langchain-0.3.18\nSuccessfully installed PyPDF2-3.0.1 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.5 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.9 filetype-1.2.0 google-ai-generativelanguage-0.6.15 google-generativeai-0.8.4 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 importlib-metadata-8.4.0 kubernetes-32.0.1 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.54 langchain-google-genai-2.0.10 langchain-text-splitters-0.3.8 langgraph-0.3.30 langgraph-checkpoint-2.0.24 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.61 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.21.1 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 ormsgpack-1.9.1 posthog-3.25.0 pydantic-settings-2.9.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.0 starlette-0.45.3 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5\n✅ Libraries installed (including langgraph>=0.3.30)\n✅ Libraries installed (0.8.4 / 0.6.15 pair)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# [2] Core Library Imports & Version Check\n---\nImports essential libraries for parsing, RAG, LangGraph flow, and Gemini interaction.  \nAlso verifies library versions to ensure compatibility across environments.","metadata":{}},{"cell_type":"code","source":"# Import core libraries\n# core libraries\nimport importlib.metadata as im\nimport google.generativeai as genai\nimport langchain, langgraph\n\n# critical modules\nfrom langchain_google_genai import (\n    ChatGoogleGenerativeAI,\n    GoogleGenerativeAIEmbeddings\n)\nfrom langchain.vectorstores import Chroma\nfrom langchain.chains import RetrievalQA\nfrom langgraph.graph import StateGraph, END\nfrom typing import TypedDict\n# API\nfrom kaggle_secrets import UserSecretsClient\n# utilities\n#from pypdf import PdfReader\n#from pdf2image import convert_from_path\n#import pytesseract\nimport pandas as pd, os, re, textwrap, json\nimport logging\nimport PyPDF2\n\n\nlogging.basicConfig(level=logging.INFO, format=\"%(message)s\")\nlogger = logging.getLogger(__name__)\n\nprint(\"Versions\")\nfor pkg in (\n    \"google-generativeai\",\n    \"google-ai-generativelanguage\",\n    \"langchain\",\n    \"langchain-google-genai\",\n    \"langgraph\",\n    \"langchain-core\",\n):\n    print(\"   •\", pkg, \":\", im.version(pkg))\nprint(\"✅ Versions checked\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:24:08.765286Z","iopub.execute_input":"2025-04-19T15:24:08.765618Z","iopub.status.idle":"2025-04-19T15:24:13.113205Z","shell.execute_reply.started":"2025-04-19T15:24:08.765584Z","shell.execute_reply":"2025-04-19T15:24:13.112035Z"}},"outputs":[{"name":"stdout","text":"Versions\n   • google-generativeai : 0.8.4\n   • google-ai-generativelanguage : 0.6.15\n   • langchain : 0.3.23\n   • langchain-google-genai : 2.0.10\n   • langgraph : 0.3.30\n   • langchain-core : 0.3.54\n✅ Versions checked\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# [3] API Configuration & Gemini Initialization\n---\nSets up the Gemini Flash 2.5 API for text generation and embedding.  \nCredentials are securely handled via Kaggle’s environment.  \nAlso configures model endpoints used in resume rewriting and RAG chains.","metadata":{}},{"cell_type":"code","source":"# Set up API key\nsecrets = UserSecretsClient()\nAPI_KEY = secrets.get_secret(\"JRAA_Gemini_API\")\n\ngenai.configure(api_key=API_KEY)\nos.environ[\"GOOGLE_API_KEY\"] = API_KEY          # optional, but handy for other libs\n\nprint(\"✅ API key configured\")\n\nllm_chat  = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")   # LangChain wrapper\nllm_flash = genai.GenerativeModel(\"gemini-1.5-flash\")          # Direct SDK handle\n\nprint(\"✅ Gemini 1.5 Flash ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:24:46.037136Z","iopub.execute_input":"2025-04-19T15:24:46.037644Z","iopub.status.idle":"2025-04-19T15:24:46.313763Z","shell.execute_reply.started":"2025-04-19T15:24:46.037617Z","shell.execute_reply":"2025-04-19T15:24:46.312736Z"}},"outputs":[{"name":"stdout","text":"✅ API key configured\n✅ Gemini 1.5 Flash ready\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# [4] PDF Text Extraction\n---\nExtracts resume content from PDF files using `PyPDF2`.  \nOCR fallback via Tesseract was planned but not used in the final version due to parsing reliability.","metadata":{}},{"cell_type":"code","source":"def extract_text_from_pdf(path: str) -> str:\n    \"\"\"\n    Extracts all text from each PDF page using PyPDF2.\n    Does not perform any OCR fallback.\n    \"\"\"\n    reader = PyPDF2.PdfReader(path)\n    return \"\\n\".join(page.extract_text() or \"\" for page in reader.pages)\nprint(\"✅ PyPDF2.PdfReader\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:25:00.054350Z","iopub.execute_input":"2025-04-19T15:25:00.054671Z","iopub.status.idle":"2025-04-19T15:25:00.060385Z","shell.execute_reply.started":"2025-04-19T15:25:00.054647Z","shell.execute_reply":"2025-04-19T15:25:00.059490Z"}},"outputs":[{"name":"stdout","text":"✅ PyPDF2.PdfReader\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# [5] UX Insight Embeddings & RAG Setup\n---\nLoads bilingual UX survey data and converts it into embeddings using Gemini.  \nThe insights are stored in ChromaDB and used to generate personalized job advice via Retrieval-Augmented Generation (RAG).","metadata":{}},{"cell_type":"code","source":"# Load UX Survey + Seed Advice\ndf = pd.read_json(\"/kaggle/input/ux-survey-career-japan/ux_survey.json\")\nux_insights = df.dropna(subset=[\"Please describe specific obstacles\"])\\\n                .apply(lambda r: f\"{r['Please describe specific obstacles']} \"\n                                f\"(Visa: {r['Current Visa Status']}, JP: {r['Your Japanese Language Proficiency Level']})\",\n                       axis=1).tolist()\n\n\n# Define seeds\njob_advice_seeds = [\n    \"In Japan, it's important to include your JLPT level and photo on your resume.\",\n    \"Recruiters expect short and formal 自己PR statements. Don't write more than 300 words.\",\n    \"N4 is acceptable for entry-level or technical roles, but more companies prefer N3 or above.\",\n    \"If you want to work in tech, learn some basic business Japanese (keigo expressions like お世話になります).\",\n    \"Try mixing Japanese and English job boards to maximize exposure.\",\n    \"Many companies in Japan follow fixed hiring cycles (like April or October). Timing your application can improve response rates.\",\n    \"Japanese interviews often include questions like 'Why Japan?' or 'What do you know about our company?' Be prepared to answer these.\",\n    \"Avoid vague or overly casual expressions in 自己PR. Japanese recruiters value humility and clear structure.\"\n] + ux_insights\n# Setup RAG chain\nemb = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n\njob_advice_retriever = Chroma.from_texts(\n    job_advice_seeds,\n    embedding=emb\n).as_retriever(k=3)\n\nrag_chain = RetrievalQA.from_chain_type(\n    llm=llm_chat,\n    retriever=job_advice_retriever,\n    return_source_documents=False\n)\n\nprint(\"✅ RAG chain ready with\", len(job_advice_seeds), \"snippets\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:25:33.144175Z","iopub.execute_input":"2025-04-19T15:25:33.144503Z","iopub.status.idle":"2025-04-19T15:25:34.374652Z","shell.execute_reply.started":"2025-04-19T15:25:33.144477Z","shell.execute_reply":"2025-04-19T15:25:34.373712Z"}},"outputs":[{"name":"stdout","text":"✅ RAG chain ready with 24 snippets\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# [6] Tool Functions","metadata":{}},{"cell_type":"markdown","source":"## [6.1] CV Parsing & JSON Extraction\n---\nUses Gemini to extract structured fields from uploaded Japanese résumés.  \nReturns a JSON object containing name, education, skills, certifications, 自己PR, and more.","metadata":{}},{"cell_type":"code","source":"def parse_cv_node(cv_path: str) -> dict:\n    print(\"[Outside loop] Running parse_cv_node\")\n    raw_cv = extract_text_from_pdf(cv_path)\n    prompt = (\n        \"Extract the following fields and return ONLY valid JSON:\\n\"\n        \"- name, dob, nationality, address, phone, email,\\n\"\n        \"- education (list of strings), work_experience, certifications, skills,\\n\"\n        \"- self_pr, motivation\\n\\n\"\n        + raw_cv\n    )\n    out = llm_flash.generate_content(prompt).text.strip()\n    m = re.search(r\"\\{.*\\}\", out, re.S)\n    if not m:\n        raise ValueError(f\"JSON parse failed:\\n{out}\")\n    parsed = json.loads(m.group(0))\n    print(\"✅ Parsed CV JSON:\")\n    return {\"raw_cv\": raw_cv, \"parsed_cv\": parsed}\n\nCV_PATH = \"/kaggle/input/sample/Daniel-Thompson-Resume.pdf\"\nparsed = parse_cv_node(CV_PATH)\nraw_cv, parsed_cv = parsed[\"raw_cv\"], parsed[\"parsed_cv\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:25:56.322932Z","iopub.execute_input":"2025-04-19T15:25:56.323307Z","iopub.status.idle":"2025-04-19T15:26:01.577734Z","shell.execute_reply.started":"2025-04-19T15:25:56.323283Z","shell.execute_reply":"2025-04-19T15:26:01.576803Z"}},"outputs":[{"name":"stdout","text":"[Outside loop] Running parse_cv_node\n✅ Parsed CV JSON:\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## [6.2.1] Tailor CV Node — Rewrite 自己PR & 志望動機\n---\nGenerates formal Japanese self-promotion and motivation statements tailored to the target company.  \nUses few-shot prompting with structured resume input and optional company info.","metadata":{}},{"cell_type":"code","source":"def tailor_cv_node(state: dict) -> dict:\n    import re\n\n    # Utility: count Japanese (non-ASCII) characters\n    def count_japanese_chars(s: str) -> int:\n        return sum(1 for ch in s if ord(ch) > 127)\n\n    company      = state[\"company\"]\n    raw          = state[\"raw_cv\"]\n    cv           = state[\"parsed_cv\"]\n\n    # Retrieve company info (fallback to LLM if not found)\n    company_info = retrieve_company_info(company)\n    if not company_info:\n        company_info = llm_flash.generate_content(\n            f\"Provide the mission, values, and recent highlights of {company}.\"\n        ).text.strip()\n\n    # Build the rewrite prompt using structured rules\n    prompt = (\n        # No emojis, no placeholders\n        \"Output starting with ENGLISH short reply for example Here's your rewrite resume. or Rewrite version to align with {company}\\n\"\n        \"Please output ONLY the resume content—no emojis, no “🤖” markers, no text in brackets. \"\n        \"Use the actual names from the extracted fields. If some name is missing, substitute a generic term.\\n\\n\"\n        # Formatting rules\n        \"- Use Japanese résumé conventions (履歴書), formal tone.\\n\"\n        \"- Append English translations in parentheses immediately after each Japanese line.\\n\"\n        \"- List jobs in reverse‑chronological order with consistent bullet length.\\n\"\n        \"- 自己PRは200～300文字以内で作成してください。\\n\"\n        \"- 志望動機は200～300文字以内で作成してください。\\n\"\n        \"- Incorporate 貴社 into the 自己PR section to demonstrate respect.\\n\\n\"\n        # Rewrite instruction\n        f\"Rewrite the entire CV to align with {company}:\\n\\n\"\n        f\"氏名: {cv['name']}\\n\"\n        f\"生年月日・国籍: {cv['dob']}／{cv['nationality']}\\n\"\n        f\"住所・連絡先: {cv['address']}／{cv['phone']}／{cv['email']}\\n\\n\"\n        \"学歴:\\n\" + \"\\n\".join(f\"  * {e}\" for e in cv[\"education\"]) + \"\\n\\n\"\n        \"職務経歴:\\n\" + \"\\n\".join(f\"  * {e}\" for e in cv[\"work_experience\"]) + \"\\n\\n\"\n        \"資格:\\n\" + \"\\n\".join(f\"  * {c}\" for c in cv[\"certifications\"]) + \"\\n\\n\"\n        \"スキル:\\n\" + \"\\n\".join(f\"  * {s}\" for s in cv[\"skills\"]) + \"\\n\\n\"\n        f\"自己PR: {cv['self_pr']}\\n\\n\"\n        f\"志望動機: {cv['motivation']}\\n\\n\"\n        # Company context\n        f\"※Company Info for {company}:\\n{company_info}\\n\"\n    )\n\n    # Generate initial rewrite\n    result = llm_flash.generate_content(prompt).text.strip()\n\n    # Enforce 自己PR length (200–300 Japanese characters)\n    match = re.search(r\"自己PR:\\s*(.+?)(?:\\n\\n|$)\", result, re.S)\n    if match:\n        jiko_pr = match.group(1).strip()\n        length  = count_japanese_chars(jiko_pr)\n        if length < 200 or length > 300:\n            followup = f\"Your 自己PR is {length}文字です。200～300文字になるよう調整してください。\"\n            result   = llm_flash.generate_content(prompt + \"\\n\\n\" + followup).text.strip()\n\n    return {**state, \"result\": result}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:26:21.448869Z","iopub.execute_input":"2025-04-19T15:26:21.449745Z","iopub.status.idle":"2025-04-19T15:26:21.459832Z","shell.execute_reply.started":"2025-04-19T15:26:21.449716Z","shell.execute_reply":"2025-04-19T15:26:21.458998Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## [6.2.2] Company Info Retrieval\n---\nFetches mission, values, and recent highlights of the target company using Gemini.  \nThis context is embedded into the CV rewriting prompt to improve personalization.","metadata":{}},{"cell_type":"code","source":"def retrieve_company_info(company: str) -> str:\n    #print(\"✅ retrieve_company_info\")\n    # Simulate a database or web fetch #this can change into RAG in the future develop\n    dummy_info = {\n        \"Capcom\": \"Capcom is a global video game developer known for Resident Evil and Monster Hunter.\",\n        \"Rakuten\": \"Rakuten is a Japanese e-commerce and internet services company with a global presence.\",\n        \"Toyota\": \"Toyota is a leading automotive company focused on innovation and sustainability.\"\n    }\n    #print(\"✅ Exit retrieve_company_info\")\n    return dummy_info.get(company, f\"{company} is a company in Japan. More details are not available.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:26:38.864491Z","iopub.execute_input":"2025-04-19T15:26:38.864817Z","iopub.status.idle":"2025-04-19T15:26:38.870088Z","shell.execute_reply.started":"2025-04-19T15:26:38.864785Z","shell.execute_reply":"2025-04-19T15:26:38.869244Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## [6.3] UX Advice Node — RAG-Based Career Support\n---\nGenerates personalized job advice using RAG.  \nCombines user certifications (JLPT, TOEIC) with embedded UX survey insights to recommend actionable next steps for working in Japan.","metadata":{}},{"cell_type":"code","source":"def job_advice_node(state: dict) -> dict:\n    \"\"\"\n    Use RAG to answer the user's own query (e.g. “give me job advice”),\n    grounded in their profile and the UX survey insights.\n    Enforce a consistent, numbered format but let the user dictate the task.\n    \"\"\"\n    cv      = state[\"parsed_cv\"]\n    query   = state[\"query\"]  # e.g. \"give me job advice\"\n    \n    # Extract the user's real certification data\n    jlpt    = next((c for c in cv[\"certifications\"] if \"日本語能力試験\" in c),\n                   \"日本語能力試験 N? 未取得\")\n    toeic   = next((c for c in cv[\"certifications\"] if \"TOEIC\" in c),\n                   \"TOEIC 未取得\")\n    skills  = \", \".join(cv[\"skills\"])\n    \n    # Fold in UX survey bullet points\n    ux_ctx  = \"\\n\".join(f\"- {tip}\" for tip in ux_insights)\n    \n    # Guard‑rails on formatting, independent of the user task\n    formatting = (\n        \"Output your answer as a numbered list with at least 3 items (unless the user's request \"\n        \"specifies otherwise). For each item:\\n\"\n        \"  1. Bold the title of the item.\\n\"\n        \"  2. On the next line, prefix “- Advice:” for a brief action.\\n\"\n        \"  3. On a following line, prefix “- Resources:” for links or tools (if applicable).\\n\"\n        \"All output must be in English; Japanese words are allowed only with translations in parentheses.\\n\\n\"\n    )\n    \n    # Build the dynamic prompt\n    prompt = (\n        formatting +\n        \"Candidate profile:\\n\"\n        f\"- {jlpt}\\n\"\n        f\"- {toeic}\\n\"\n        f\"- Skills: {skills}\\n\"\n        f\"- QA roles: {len(cv['work_experience'])}\\n\\n\"\n        \"UX survey insights (reported barriers):\\n\"\n        f\"{ux_ctx}\\n\\n\"\n        \"User request:\\n\"\n        f\"{query}\\n\\n\"\n        \"Please answer the user's request above, following the formatting rules.\"\n    )\n    \n    # Invoke RAG (use invoke to avoid deprecation)\n    raw_output = rag_chain.invoke({\"query\": prompt})\n    \n    # Extract the string if we got a dict\n    advice_text = raw_output.get(\"result\", raw_output) if isinstance(raw_output, dict) else raw_output\n    \n    # Ensure real line breaks\n    advice = advice_text.replace(\"\\\\n\", \"\\n\")\n    \n    return {**state, \"result\": advice}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:27:50.251889Z","iopub.execute_input":"2025-04-19T15:27:50.252728Z","iopub.status.idle":"2025-04-19T15:27:50.260715Z","shell.execute_reply.started":"2025-04-19T15:27:50.252702Z","shell.execute_reply":"2025-04-19T15:27:50.259762Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## [6.4] Alternative Job Suggestion Node\n---\nSuggests 5 alternative job paths based on the user’s parsed resume profile.  \nUses Gemini to generate role suggestions, stores them temporarily in a Chroma vector index, and retrieves the most relevant ones.  \nSupports structured, RAG-style output with Japanese terms and translations.","metadata":{}},{"cell_type":"code","source":"def recommend_alt_jobs_node(state: dict) -> dict:\n    \"\"\"\n    Suggest 5 alternative job roles in Japan from the Resume below,\n    and format each item as:\n      1. **<Job Title in English>** (<Japanese title>):\n         - Transition Advice: …\n         - Recommended Courses/Skills: …\n    Permit Japanese words only with translations in ().\n    \"\"\"\n\n    raw_cv = state[\"raw_cv\"]\n\n    # Build a structured prompt\n    prompt = (\n        # Formatting guard rails\n        \"Output exactly 5 numbered items. For each:\\n\"\n        \"  1. Bold the English job title and put the Japanese title in parentheses.\\n\"\n        \"  2. On the next line, prefix “- Transition Advice:” and give a 1‑sentence tip.\\n\"\n        \"  3. On the following line, prefix “- Recommended Courses/Skills:” and list any study suggestions.\\n\"\n        \"All output must be in English. Japanese words are allowed only with an English translation in parentheses.\\n\\n\"\n        # What to base it on\n        \"Suggest alternative roles based on this résumé:\\n\\n\"\n        f\"{raw_cv}\\n\"\n    )\n\n\n    # Call the LLM\n    text = llm_flash.generate_content(prompt).text\n\n    # Split into individual non-empty lines\n    suggestions = [line for line in text.splitlines() if line.strip()]\n\n    # Join back into a clean multi-line string\n    result_text = \"\\n\".join(suggestions)\n\n    return {**state, \"result\": result_text}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:28:09.723826Z","iopub.execute_input":"2025-04-19T15:28:09.724843Z","iopub.status.idle":"2025-04-19T15:28:09.730685Z","shell.execute_reply.started":"2025-04-19T15:28:09.724807Z","shell.execute_reply":"2025-04-19T15:28:09.729828Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def build_alt_job_store(profile: str):\n\n    \"\"\"\n    Returns a Chroma retriever seeded with alternative‑job snippets,\n    ready to query using the candidate's raw CV text.\n    \"\"\"\n    # alt_job_snippets is a list of strings you prepared earlier\n    return Chroma.from_texts(\n        alt_job_snippets,      # your 4–5 prewritten alternative‑job doc strings\n        embedding=emb\n    ).as_retriever(k=5)\n\n    \n    #print(\"🧭 Enter build_alt_job_store\")\n    prompt = (\n        \"Suggest 5 alternative job roles in Japan from the data you get from the Resume below.\"\n        \"Return each suggestion as one sentence and also include Advice about transition into a new position.\"\n        \"If you have some recommended course or skill set, recommend it.\"\n        \"PLEASE NOTE THAT ANSWER MUST BE IN ENGLISH, You can use Japanese for important WORD but you have to add () and write translation inside after that word\\n\\n\" + profile\n    )\n    suggestions = llm_flash.generate_content(prompt).text.splitlines()\n\n    # ✅ In-memory only — avoids persistence errors\n    return Chroma.from_texts(suggestions, embedding=emb).as_retriever(k=2)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:28:19.700646Z","iopub.execute_input":"2025-04-19T15:28:19.700987Z","iopub.status.idle":"2025-04-19T15:28:19.707005Z","shell.execute_reply.started":"2025-04-19T15:28:19.700933Z","shell.execute_reply":"2025-04-19T15:28:19.705895Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# [7] LangGraph Agent Flow & Routing\n---\nDefines the LangGraph architecture used to control chatbot flow.  \nRoutes user input dynamically to the correct node based on intent (e.g., rewrite resume, get advice, explore new jobs).  \nEach node reads and updates shared state using a dictionary-based agent state model.","metadata":{}},{"cell_type":"code","source":"# Shared State\nclass AgentState(TypedDict):\n    query: str\n    result: str\n    company: str\n    parsed_cv: str  # Optional but useful in CV use case\n    raw_cv: str\n\n# Routing Logic\ndef route(state: AgentState) -> str:\n    #print(\"📊 Full State Contents:\")\n    \n    if \"raw_cv\" not in state:\n        state[\"raw_cv\"] = raw_cv\n        \n    for key, value in state.items():\n        preview = str(value)[:100].replace(\"\\n\", \" \")\n        #print(f\"🔑 {key}: {preview}...\")\n\n    query = state.get(\"query\", \"\").lower()\n    if any(keyword in query for keyword in [\"rewrite\", \"志望動機\", \"resume\", \"自己pr\"]):\n        #print(\"➡️ Routing to: tailor_cv_node\")\n        return \"tailor_cv_node\"\n        \n    elif any(keyword in query for keyword in [\"job advice\", \"how to find job\", \"how can i get a job\", \"career advice\", \"how to apply\", \"job in japan\"]):\n        #print(\"➡️ Routing to: job_advice_node\")\n        return \"job_advice_node\"\n\n    elif any(keyword in query for keyword in [\"alternative job\", \"job suit\", \"recommend job\", \"what job\", \"career\", \"仕事\", \"職種\"]):\n        #print(\"➡️ Routing to: recommend_alt_jobs\")\n        return \"recommend_alt_jobs\"\n\n    print(\"🛑 No match — ending flow\")\n    return \"default_fallback\"\n\n\n# Build the Graph\nbuilder = StateGraph(AgentState)\n\n# Only add actual processing nodes\nbuilder.add_node(\"tailor_cv_node\", tailor_cv_node)\nbuilder.add_node(\"job_advice_node\", job_advice_node)\nbuilder.add_node(\"recommend_alt_jobs\", recommend_alt_jobs_node)\n\nbuilder.set_entry_point(\"start_router\")  # pick a new internal router node\n\n# Register a dummy node to represent router\ndef router_entry_node(state: AgentState) -> AgentState:\n    print(\"🚦 Initial router node\")\n    return state\n\nbuilder.add_node(\"start_router\", router_entry_node)\n\n# Then update your conditional routing:\nbuilder.add_conditional_edges(\"start_router\", route, {\n    \"tailor_cv_node\": \"tailor_cv_node\",\n    \"job_advice_node\": \"job_advice_node\",\n    \"recommend_alt_jobs\": \"recommend_alt_jobs\",\n    \"default_fallback\": END\n})\n\n# Optional: loop back to router if needed\n# builder.add_edge(\"tailor_cv_node\", \"router\")\n# builder.add_edge(\"ux_advice\", \"router\")\n# builder.add_edge(\"recommend_alt_jobs\", \"router\")\n\n# Compile\nmulti_agent = builder.compile()\nprint(\"✅ Builder Compiled\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:29:11.271672Z","iopub.execute_input":"2025-04-19T15:29:11.271993Z","iopub.status.idle":"2025-04-19T15:29:11.291298Z","shell.execute_reply.started":"2025-04-19T15:29:11.271935Z","shell.execute_reply":"2025-04-19T15:29:11.290256Z"}},"outputs":[{"name":"stdout","text":"✅ Builder Compiled\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# [8] Chatbot Simulation Loop\n---\nRuns an interactive chatbot loop using the LangGraph agent.  \nSupports natural user queries like “rewrite my resume” or “give me job advice,” routing them to the correct tool.  \nIdeal for testing resume rewrites, advice generation, and job recommendations in real time.","metadata":{}},{"cell_type":"code","source":"def chatbot_simulator():\n    print(\"🤖 JobBridge‑AI: Welcome to JobBridge‑AI!\")\n    print(\"💬 Type: “rewrite my resume”, “give me job advice”, or “suggest alternative jobs”\")\n    print(\"🛑 Quit with q / quit / exit\\n\")\n\n    while True:\n        user_input = input(\"🧠 You: \").strip()\n        if user_input.lower() in {\"q\", \"quit\", \"exit\"}:\n            print(\"👋 Ending Session\")\n            break\n\n        state = {\n            \"raw_cv\":    raw_cv,\n            \"parsed_cv\": parsed_cv,\n            \"query\":     user_input,\n            \"company\":   \"\"\n        }\n        if \"rewrite\" in user_input.lower():\n            state[\"company\"] = input(\"🏢 Which company? \").strip()\n\n        #print(\"🌀 Running agent flow…\")\n        response = multi_agent.invoke(state)\n\n        # Extract and clean the advice string\n        advice = response.get(\"result\", \"⚠️ No result returned.\")\n        advice = advice.replace(\"\\\\n\", \"\\n\")\n\n        # Print it out—using the same variable name!\n        print(\n            f\"\\n🤖 JobBridge‑AI:\\n\"\n            f\"{advice}\\n\"\n            f\"{'-'*40}\\n\"\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:29:30.138780Z","iopub.execute_input":"2025-04-19T15:29:30.139710Z","iopub.status.idle":"2025-04-19T15:29:30.146466Z","shell.execute_reply.started":"2025-04-19T15:29:30.139683Z","shell.execute_reply":"2025-04-19T15:29:30.145231Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Execute Program","metadata":{}},{"cell_type":"code","source":"chatbot_simulator()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:29:52.187704Z","iopub.execute_input":"2025-04-19T15:29:52.188072Z","iopub.status.idle":"2025-04-19T15:30:42.962041Z","shell.execute_reply.started":"2025-04-19T15:29:52.188050Z","shell.execute_reply":"2025-04-19T15:30:42.961127Z"}},"outputs":[{"name":"stdout","text":"🤖 JobBridge‑AI: Welcome to JobBridge‑AI!\n💬 Type: “rewrite my resume”, “give me job advice”, or “suggest alternative jobs”\n🛑 Quit with q / quit / exit\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"🧠 You:  rewrite my resume\n🏢 Which company?  Rakuten\n"},{"name":"stdout","text":"🚦 Initial router node\n\n🤖 JobBridge‑AI:\nHere's your rewritten resume.\n\n氏名: Daniel Thompson (Name: Daniel Thompson)\n生年月日・国籍: 1992年5月14日／ニュージーランド国籍 (Date of Birth・Nationality: May 14, 1992 / New Zealand)\n住所・連絡先: 〒150-0002 東京都渋谷区渋谷2-15-1 渋谷クロスタワー24階／080-1234-5678／daniel.t@example.com (Address・Contact: Shibuya Crosta Tower 24F, 2-15-1 Shibuya, Shibuya-ku, Tokyo 150-0002 / 080-1234-5678 / daniel.t@example.com)\n\n学歴:\nオークランド大学 メディア・コミュニケーション学部 卒業 (Auckland University, Graduate, Faculty of Media and Communication)\n\n職務経歴:\n渋谷日本語センター  (Shibuya Japanese Language Center)\n期間: 2019年1月～現在 (Period: January 2019 – Present)\n・（職務内容を記述）(Description of duties)\n\nScriptWorks　広告代理店 (ScriptWorks, Advertising Agency)\n期間: 2010年4月～2018年12月 (Period: April 2010 – December 2018)\n・脚本、コピーライティング業務に従事 (Engaged in scriptwriting and copywriting)\n・多文化チームとの協働によるプロジェクト多数経験 (Experienced in numerous projects collaborating with multicultural teams)\n・クライアントニーズに沿った効果的な広告制作に貢献 (Contributed to effective advertisement production aligned with client needs)\n\n\n資格:\nTESOL（英語教育資格）(TESOL (English Language Teaching Certificate))\n日本語能力試験 N2 合格 (Japanese Language Proficiency Test N2)\n\nスキル:\n日本語（ビジネス会話レベル）(Japanese (Business Conversational Level))\n英語（ネイティブ）(English (Native))\nスクリプトライティング・コピーライティング (Scriptwriting and Copywriting)\nAdobe Creative Cloud（Photoshop, Premiere Pro）(Adobe Creative Cloud (Photoshop, Premiere Pro))\nGoogle Workspace・Notion・Slack (Google Workspace, Notion, Slack)\n\n\n自己PR:\nニュージーランド出身のメディア専門家です。3年以上に渡り日本の教育機関でALTとして勤務し、日本文化への深い理解と、多様なバックグラウンドを持つ方々との円滑なコミュニケーション能力を培ってきました。前職の広告代理店での経験を通して、多文化チームでの協働、効果的なストーリーテリング、クライアントニーズへの的確な対応を学びました。日本語能力試験N2取得済みであり、ビジネスレベルの日本語運用能力を有しています。貴社のグローバルな事業展開において、培ってきた表現力と異文化コミュニケーション能力を活かし、正確で魅力的なコンテンツ制作に貢献したいと考えています。(I am a media professional from New Zealand.  For over three years, I have worked as an ALT in Japanese educational institutions, cultivating a deep understanding of Japanese culture and smooth communication skills with people from diverse backgrounds. My experience at an advertising agency has taught me collaboration in multicultural teams, effective storytelling, and responding accurately to client needs. I have passed the Japanese Language Proficiency Test N2 and possess business-level Japanese proficiency.  I believe my honed communication skills and intercultural understanding can contribute to the creation of accurate and engaging content for Rakuten's global business expansion.)\n\n\n志望動機:\n楽天株式会社のグローバルな事業展開と、多様なサービスに魅力を感じております。特に、世界中のユーザーにサービスを提供する上でのローカライゼーションの重要性を強く認識しており、私の経験とスキルが貴社に貢献できると確信しております。ニュージーランドの広告代理店でのコピーライティング経験、そして日本の教育現場でのALT経験を通して培ってきた、正確な表現力と多文化理解を活かし、貴社のサービスをより多くのユーザーにとって親しみやすく、価値のあるものにするために尽力したいと考えています。英語ネイティブとしての強みと日本語能力を活かし、国際的なコミュニケーションの架け橋として、貴社の発展に貢献できることを願っております。(I am attracted to Rakuten's global business expansion and diverse services. I strongly believe in the importance of localization in delivering services to users worldwide, and I am confident that my experience and skills will contribute significantly to Rakuten. Through my copywriting experience at a New Zealand advertising agency and my ALT experience in Japanese education, I have developed accurate expression skills and cross-cultural understanding. I want to leverage these skills to make Rakuten's services more user-friendly and valuable for a wider audience. As a native English speaker with Japanese language proficiency, I aspire to serve as a bridge in international communication and contribute to Rakuten's continued growth.)\n----------------------------------------\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"🧠 You:  give me job advice\n"},{"name":"stdout","text":"🚦 Initial router node\n\n🤖 JobBridge‑AI:\n1. **Target English-Speaking Companies**\n\n- Advice: Focus your job search on multinational companies or foreign companies based in Japan.  These companies are often more open to hiring candidates with strong English skills and may be less stringent about Japanese language proficiency, especially for entry-level positions.\n\n- Resources: Websites like Indeed Japan, LinkedIn, and Glassdoor can be filtered to show English-speaking companies.\n\n\n2. **Network Strategically**\n\n- Advice: Leverage your existing network and actively build new connections within your field. Attend industry events (even online ones), join relevant online communities, and reach out to people working in your target roles at companies you admire. Networking can open doors to unadvertised positions and provide valuable insights.\n\n- Resources: LinkedIn, Meetup.com, industry-specific online forums.\n\n\n3. **Highlight Transferable Skills**\n\n- Advice: Emphasize the transferable skills from your QA experience that are relevant to UX roles, even if you lack direct experience in UX. Your scripting and copywriting skills, combined with your experience in QA, could be valuable assets.  Showcase your proficiency with Adobe Creative Cloud and Google Workspace in your resume and cover letter, highlighting projects where you utilized these tools.\n\n- Resources:  Resume and cover letter templates, online portfolio platforms (Behance, Dribbble).\n\n\n4. **Address the Japanese Language Barrier Proactively**\n\n- Advice: While focusing on English-speaking opportunities, acknowledge your Japanese language skills (N2) in your applications.  This demonstrates your commitment to working in Japan and your willingness to learn.  Consider taking additional Japanese language courses to further improve your proficiency.  If the company uses Japanese in their workplace, be honest about your level and express your eagerness to improve.\n\n- Resources:  Japanese language learning apps (Duolingo, Memrise), online Japanese language courses (Coursera, edX).\n\n\n5. **Prepare for Japanese-Style Interviews**\n\n- Advice: Research Japanese interview etiquette and prepare for potential questions that go beyond your technical skills.  Practice answering behavioral questions and be ready to discuss your career goals and how you align with the company's culture.  Having a solid understanding of Japanese business culture will be beneficial.\n\n- Resources: Websites and articles on Japanese business culture and interview etiquette.\n\n\n6. **Consider Entry-Level Roles in Related Fields**\n\n- Advice: If finding a direct entry-level UX role proves difficult, consider applying for entry-level positions in related fields (e.g., technical writing, content creation) within English-speaking companies. This can provide valuable experience that will make you a more competitive candidate for UX roles in the future.\n\n- Resources: Job boards, company websites.\n----------------------------------------\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"🧠 You:  suggest alternative jobs\n"},{"name":"stdout","text":"🚦 Initial router node\n\n🤖 JobBridge‑AI:\n1. **Copywriter** (コピーライター)\n- Transition Advice: Leverage your experience in script and copywriting at ScriptWorks to highlight your creative abilities and adaptability to new industries.\n- Recommended Courses/Skills:  Advanced copywriting techniques, SEO copywriting, content marketing,  Japanese business writing.\n2. **Localization Specialist** (ローカリゼーションスペシャリスト)\n- Transition Advice:  Showcase your native English fluency, N2 Japanese proficiency, and experience working in multicultural teams to demonstrate your suitability for this role.\n- Recommended Courses/Skills: Translation (especially Japanese-English), localization management, cultural sensitivity training, software localization tools (e.g., SDL Trados).\n3. **Content Creator** (コンテンツクリエイター)\n- Transition Advice: Highlight your experience creating marketing materials at ScriptWorks and your ability to adapt your content to different audiences, emphasizing your bilingual skills.\n- Recommended Courses/Skills: Content strategy, social media marketing, video editing, graphic design (if applicable),  multilingual content creation.\n4. **Technical Writer** (テクニカルライター)\n- Transition Advice: Your experience with scriptwriting and your attention to detail will translate well to this field; emphasize your ability to explain complex information clearly and concisely.\n- Recommended Courses/Skills: Technical writing principles, documentation software (e.g., MadCap Flare),  API documentation,  user interface (UI) writing.\n5. **Marketing Manager (Entry-Level)** (マーケティングマネージャー (初級))\n- Transition Advice: Frame your experience at ScriptWorks as a foundation for understanding marketing strategies and managing projects, emphasizing your communication and teamwork skills.\n- Recommended Courses/Skills: Marketing fundamentals, digital marketing, project management, marketing analytics,  Japanese business etiquette.\n----------------------------------------\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"🧠 You:  Quit\n"},{"name":"stdout","text":"👋 Ending Session\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## -------------------------------------------\n","metadata":{}}]}