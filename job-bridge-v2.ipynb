{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11424740,"sourceType":"datasetVersion","datasetId":7155164},{"sourceId":11431894,"sourceType":"datasetVersion","datasetId":7160041}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 🔍 Introduction\n---\n**JobBridge-AI** is a research-driven UX and AI Capstone project developed as part of the *Gen AI Intensive Course*.<br>\nIt tackles real-world challenges faced by foreigners seeking employment in Japan — challenges I personally experienced while navigating the Japanese job market.<br>\n\nMotivated by those experiences, I built JobBridge-AI to explore user pain points and design smarter, more supportive tools.<br>\nBy leveraging **Generative AI** technologies like Google Gemini, LangChain, and LangGraph, the system delivers personalized résumé feedback, UX advice, and culturally-aware career suggestions based on user questions and uploaded CVs.","metadata":{}},{"cell_type":"markdown","source":"# 🗻 Why Japan\n---\nJapan is a unique job market with strong local hiring customs, a high emphasis on language ability, and limited resources tailored to non-Japanese speakers.<br>\nFor many foreigners from students and new graduates to mid-career professionals —  \nthe job search process can feel confusing and isolating.<br>\n\nMany job seekers face barriers including language proficiency (N2/N1), lack of sponsorship, and mismatch with recruiter expectations.<br>\nThey struggle to navigate Japanese job platforms, understand resume formats (like 履歴書 and 職務経歴書), or prepare for bilingual interviews that blend keigo and technical Q&A.<br>\n\nWhile Japan offers exciting career opportunities for global talent, the path is not always clear.<br>\nLanguage barriers, unfamiliar application standards, and cultural differences can leave even highly qualified candidates feeling lost or overlooked.<br>\n\nWith a growing number of international students and foreign professionals entering Japan each year, there's an urgent need for smarter, more inclusive support systems.<br>  \n**JobBridge-AI** was created to help bridge that gap by combining generative AI with UX insights focused on real-world job search struggles.<br>","metadata":{}},{"cell_type":"markdown","source":"# 🎯 Project Goals\n---\nThe goal of JobBridge-AI is to empower foreign job seekers in Japan with smarter, more empathetic support during the job-hunting process.\n\n### 🎯 Key Objectives:\n- 🔍 **Identify** common frustrations in the Japanese job market through real UX research\n- 🧠 **Leverage Generative AI** to offer resume rewrites, career suggestions, and feedback\n- 🌐 **Bridge the language gap** with bilingual AI outputs and simplified UX\n- 🤖 **Build a working chatbot prototype** using LangGraph, LangChain, and Gemini","metadata":{}},{"cell_type":"markdown","source":"# 👕 Target Audience\n---\nTarget Group for This Project\nThis project focuses on foreign residents in Japan who face unique challenges in the job search process.<br>\nBased on our research goals, we identified the following key user segments:\n\n- **International Students & Language School Learners**<br>\nOften on student visas, these users are actively job hunting while balancing Japanese language classes. Many aim to transition into full-time roles in tech, hospitality, or creative fields.\n\n- **English Teachers Seeking Career Change**<br>\nMany participants reported being \"stuck\" in ALT or eikaiwa roles, despite having skills or experience in other industries. They often struggle to move out of education due to hiring bias and unclear career pathways.\n\n- **Highly Skilled Visa Holders or Employees**<br>\nThis group includes engineers, designers, or professionals on work or spouse visas. Despite strong credentials, many are overlooked due to language level, visa type, or cultural mismatch in hiring expectations.\n\nTo ensure diverse and inclusive insights, we aim to conduct UX research across these groups,<br>\ncovering a broad range of Japanese proficiency levels (N5 to N1) and multiple industries, including tech, hospitality, education, and creative sectors.","metadata":{}},{"cell_type":"markdown","source":"# 🧠 Gather User Insights\n---\nTo understand the challenges faced by foreign job seekers in Japan, we planned a mixed-method UX study targeting over 100 foreign professionals across multiple industries.<br>\nThe research included both a bilingual UX survey and in-depth interviews, conducted in English and Japanese.\n\nDespite time constraints, we successfully collected responses from **30+ foreign participants** via survey and conducted **10 individual interviews**.<br>\nThese insights became foundational to our AI training, grounding its advice in real-world frustrations.\n\n\n### 📋 1. Bilingual Survey (Google Form)\nA bilingual survey (English/Japanese) was distributed to foreign job seekers in Japan.  \nThe survey explored themes such as language proficiency, visa challenges, recruiter experiences, and job search pain points.\n\n**Top 5 reported pain points:**\n1. 🧱 **Language barrier** (especially N2+ requirement)\n2. ⚔️ **Competition with local candidates**\n3. 🔍 **Difficulty identifying suitable jobs** \n4. 🤝 **Limited networking opportunities**\n5. 🌐 **Cultural differences in interviews**\n\n**Status**: ✅ Survey completed (30+ respondents)  \n**Insights Summary**:  \nThere’s a clear demand for tools that decode job descriptions, tailor resumes, and support bilingual candidates more effectively.\n\n\n### 🗣️ 2. Individual Interviews (Google Meet)\nIn-depth interviews were conducted in English and Japanese to explore pain points in greater depth.  \nOriginally, 20+ interviews were planned, but we successfully completed 10 within the project timeline.\n\nThese sessions captured rich personal experiences and validated many of the survey's trends.\n\n**Key insights:**\n- Conflicting or vague recruiter feedback is common.\n- Several reported unethical hiring practices (e.g., unpaid “test” tasks).\n- Networking and insider referrals are seen as essential — yet inaccessible for most foreigners.\n\n**Status**: ✅ Interview sampling completed (10 participants)  \n**Insights Summary**:  \nThe job hunt is not only about language or formatting. It’s also about **clarity, trust, and fairness**.<br>\nThis underscores the need for tools that are not only smart — but also **empathetic** and culturally aware.\n\n\nData from both the survey and interviews was compiled into a bilingual JSON dataset (`ux_survey.json`)<br> and integrated into the RAG pipeline via:<br>\nux_insights → job_advice_seeds → job_advice_node","metadata":{}},{"cell_type":"markdown","source":"# 🧑‍🎨 User Personas\nPersona Media link [job-bridge-media](https://www.kaggle.com/datasets/nattaveelaws/job-bridge-media/)\n\n---\n\n## **Figure:** Persona #1 – Aya Suwanisan<br>\nAge: 22<br>\nVISA Type: Student Visa<br>\nCurrent Status: Studying Japanese language, Working part-time at an izakaya<br>\nLanguage: Japanese N3 (Intermediate), English Fluent<br>\nTarget Roles: Full-time hospitality<br><br>\n### “It feels like no one will even look at your profile if you’re not fluent  even if the job says 'English OK'.”<br>\n### Goals \n- To land her first full-time job in a restaurant that values work ethic and training, not just JLPT scores\n- To build confidence interacting with Japanese customers and co-workers\n- To transition from part-time back-of-house staff to a customer-facing or managerial role\n\n### Frustrations\n- Job posts advertise “English OK,” but interviews are conducted entirely in Japanese\n- She’s unsure what to emphasize in a Japanese-style resume or 自己PR\n- Feels discouraged when she’s ghosted after interviews or told she’s “not fluent enough”\n\nAya, 26, is a Thai student in Osaka studying Japanese while working part-time at an izakaya.<br>\nShe hopes to land a full-time role in Japan’s food service industry, but finds “English OK” job posts misleading and her N3 Japanese seen as insufficient.<br>\nShe’s eager to grow, but struggles with unclear entry paths into stable hospitality roles.\n\n---\n\n## **Figure:** Persona #2 – Daniel Thompson<br>\n### Daniel Thompson\nAge: 31<br>\nVISA Type: Work Visa<br>\nCurrent Status: Full-time English teacher in a public elementary school<br>\nLanguage: Japanese N2 (Fluent), English Native<br>\nTarget Roles: Content Creation / Creative Tech<br><br>\n### “Once you become a teacher in Japan, they can’t see you as anything else even if your resume says content creator.”<br>\n\n### Goals \n- To pivot from teaching to a full-time role in content or creative tech\n- To use his Japanese fluency and media background to create meaningful cross-cultural content\n- To build a career path beyond ALT work and grow into leadership in a creative environment\n  \n### Frustrations\n- ALT experience overshadows his previous media work. Recruiters don’t read past the first line\n- Job posts claim “English OK” but interviews are entirely in Japanese and high-context\n- Lack of clear criteria portfolios are ignored unless hosted on Japanese platforms\n### Persona Summarize\nDaniel is a New Zealand media professional working as an ALT in Tokyo.<br>\nWith a background in scriptwriting and fluent Japanese (N2), he came to Japan to pursue a career in creative content.<br>\nBut visa routes pushed him into teaching. Now three years in,<br>\nhe’s rebuilding his portfolio in Japanese and looking for companies that value cross-cultural creativity not just teaching experience.\n\n---\n## **Figure:** Persona #3 – Amira Elbaz<br>\n### Amira Elbaz\nAge: 39<br>\nVISA Type: Dependent Visa (Spouse of Permanent Resident)<br>\nCurrent Status: Freelancing remotely applying to tech roles<br>\nLanguage: Japanese N4, English Fluent<br>\nTarget Roles: Backend Developer / QA / Infrastructure<br><br>\n### “My experience is solid but no one sees it because I’m on a spouse visa and speak only N4.”<br>\n### Goals \n- To re-enter the tech industry in Japan after moving for family\n- To use her 10+ years of backend development experience\n- To join a diverse team that values real experience over paperwork\n\n### Frustrations\n- Gets filtered out for not having N2, even for roles labeled “English OK”\n- Recruiters focus on her visa instead of her résumé\n- Job boards push her toward teaching or retail, ignoring her skillset\n### Persona Summarize\nAmira is a seasoned backend engineer from Egypt, now living in Saitama on a spouse visa.<br>\nDespite 10+ years of experience, her limited Japanese and visa status often lead recruiters to overlook her.<br>\nShe’s now refining her GitHub and resume in Japanese, aiming to join a tech team that values skills over status.\n\n","metadata":{}},{"cell_type":"markdown","source":"# 🛤️ User Journeys\n---\n1. User uploads a resume PDF.\n2. The system parses it into structured fields (name, education, experience...).\n3. The user can ask the bot to:\n   - Rewrite the resume for a specific company\n   - Get job advice based on their situation\n   - Ask for alternative roles\n4. The assistant responds using:\n   - Few-shot prompts (for CV)\n   - RAG (for advice)\n   - LLM generation (for jobs)","metadata":{}},{"cell_type":"markdown","source":"# 🚀 Features Implemented\n---\nJobBridge-AI integrates multiple generative AI capabilities to support the user journey, from CV preparation to career advice.<br>\nEach feature is designed to address specific pain points identified through UX research and interviews.<br><br>\n\n| 🧩 Feature | 🧠 Capability | 🔧 Method |\n|-----------|---------------|-----------|\n| **CV Parsing** | Resume document understanding | Gemini LLM + PDF parsing pipeline |\n| **Rewrite 自己PR & 志望動機** | Few-shot + controlled generation | Prompt-based rewrite using user-uploaded CVs |\n| **UX-Driven Advice** | Retrieval-Augmented Generation (RAG) | Embedding search over user pain points (vector DB) |\n| **Recommend Alternative Jobs** | Career guidance from similar profiles | Custom retriever using ChromaDB + Gemini |\n| **Conversational Agent** | Chatbot interface with smart routing | LangGraph-based flow control and input intent detection |","metadata":{}},{"cell_type":"markdown","source":"# 🧰 Capabilities Demonstrated\n---\nThis project demonstrates multiple GenAI capabilities as required by the Kaggle x Google Capstone Challenge.<br>\nEach technique was integrated intentionally to solve a user-validated pain point.\n\n| Capability | Description | Example in Project |\n|------------|-------------|--------------------|\n| **Document Understanding** | Reads and extracts content from uploaded résumés (PDF) | CV parsing via Gemini |\n| **Few-shot Prompting** | Controlled rewriting of 自己PR and 志望動機 | Uses examples to generate company-tailored versions |\n| **Retrieval-Augmented Generation (RAG)** | Embeds and retrieves pain point data for contextual UX advice | Embedding + ChromaDB |\n| **Dynamic Routing via LangGraph** | Multi-node chatbot routing based on user intent | LangGraph nodes: parse, tailor, ux_advice, alt_jobs |\n| **Multilingual Input/Output** | Accepts and generates both English and Japanese content | All core features are bilingual |","metadata":{}},{"cell_type":"markdown","source":"# 🎨 UX Accessibility Considerations\n---\n**JobBridge-AI** was designed with empathy for real users navigating the Japanese job market — many of whom face barriers related to language, culture, and unfamiliar application systems.  \nOur design was grounded in insights from bilingual UX surveys and user interviews.\n\n---\n\n### 🧩 Accessibility Features\n- **Multilingual Support:** Accepts both English and Japanese inputs, with bilingual outputs.\n- **Automatic Resume Parsing:** Users can upload a résumé PDF without formatting knowledge — the system parses and extracts content automatically.\n- **Low Barrier to Entry:** No need for prior familiarity with Japanese resume formats like 履歴書 or 職務経歴書.\n\n---\n\n### 🫂 Inclusive Design Principles\n- Supports users across all JLPT levels (N5 to N1)\n- Accepts open-ended queries (e.g., “fix my PR” or “what job suits me?”)\n- Transparent interactions: each AI step (e.g., tailoring, advice generation) is printed with clear system labels — no \"black box\" behavior.\n\n---\n\n### ⚠️ Known Limitations\n- ❌ No support for audio input or OCR (camera-captured image CVs) at this time\n- ❌ Mobile usability is constrained due to the Kaggle Notebook interface\n- ❌ Does not yet handle handwritten resumes (手書き履歴書), which some companies still request in Japan\n","metadata":{}},{"cell_type":"markdown","source":"# 🧪 Usability Testing\n---\n### Planned Flow (Originally Intended)\n1. Build a working prototype using Gemini 2 Flash to analyze user CVs.  \n2. Invite users to test and provide feedback on language clarity, output relevance, and overall usefulness.  \n3. Collect qualitative feedback via a short follow-up form or interview.  \n4. Iterate based on input and re-test improved versions.\n\n---\n\n### 🛠 Tools (Prepared)\n- **Kaggle Notebook**: Used as the user-facing interface for rapid prototyping.  \n- **Gemini API**: Powers CV understanding, RAG, and resume rewriting logic.  \n\n---\n\n### ❌ Status: Testing Not Completed  \nDue to time limitations during the Capstone Challenge window, we were unable to run formal usability testing sessions.  \nOur team prioritized core system functionality, integration, and UX-driven logic design.\n\n---\n\n### ⚠️ Known Gaps\n- No structured user feedback has been collected yet.  \n- Improvement areas remain speculative, based on survey expectations rather than real session logs or usage data.\n\n---\n\n**Next steps (post-capstone):**  \nWe plan to conduct lightweight usability testing with foreign job seekers currently in Japan to validate and refine prompt flows, language accessibility, and overall interaction clarity.","metadata":{}},{"cell_type":"markdown","source":"# Let's start\nIn this sample, we will use the uploaded resume of Daniel Thompson, one of our personas.  \nSample Resume Screenshot : [Screenshot](https://www.kaggle.com/datasets/nattaveelaws/job-bridge-media/) <br>\nSample Resume PDF : [PDF](https://www.kaggle.com/datasets/nattaveelaws/sample)","metadata":{}},{"cell_type":"markdown","source":"# [1] Library Installation & Environment Setup\n---\nInstalls the core libraries required for this project, including Gemini, LangGraph, LangChain, and ChromaDB.  \nPDF parsing is handled via `PyPDF2`.  \nAll dependencies are pinned to ensure compatibility within the Kaggle environment.","metadata":{}},{"cell_type":"code","source":"# clean up any pre‑installed copies\n!pip uninstall -qqy google-generativeai google-ai-generativelanguage\n\n# system OCR package\n# !apt-get -qq update && apt-get -qq install -y tesseract-ocr\n\n# Python libs  ── note the explicit 0.8.4 / 0.6.15 pair, and upgrade langgraph\n!pip install -U \\\n    google-generativeai==0.8.4 \\\n    google-ai-generativelanguage==0.6.15 \\\n    langgraph==0.3.30 \\\n    langchain langchain-community langchain-google-genai \\\n    chromadb PyPDF2 pandas\n\nprint(\"✅ Libraries installed (including langgraph>=0.3.30)\")\nprint(\"✅ Libraries installed (0.8.4 / 0.6.15 pair)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:44:13.897307Z","iopub.execute_input":"2025-04-19T15:44:13.897613Z","iopub.status.idle":"2025-04-19T15:44:24.066468Z","shell.execute_reply.started":"2025-04-19T15:44:13.897590Z","shell.execute_reply":"2025-04-19T15:44:24.065294Z"}},"outputs":[{"name":"stdout","text":"Collecting google-generativeai==0.8.4\n  Using cached google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\nCollecting google-ai-generativelanguage==0.6.15\n  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: langgraph==0.3.30 in /usr/local/lib/python3.11/dist-packages (0.3.30)\nRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\nRequirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.21)\nRequirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.0.10)\nCollecting langchain-google-genai\n  Using cached langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (1.0.5)\nRequirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.4) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.4) (2.160.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.4) (2.27.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.4) (3.20.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.4) (2.11.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.4) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.4) (4.13.1)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15) (1.26.0)\nRequirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.3.30) (0.3.54)\nRequirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.3.30) (2.0.24)\nRequirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.3.30) (0.1.8)\nRequirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.3.30) (0.1.61)\nRequirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.3.30) (3.5.0)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.16)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\nRequirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\nINFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n  Using cached langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n  Using cached langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n  Using cached langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n  Using cached langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\nRequirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\nRequirement already satisfied: fastapi==0.115.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.9)\nRequirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.2)\nRequirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.25.0)\nRequirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.21.1)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.27.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.27.0)\nRequirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48b0)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.27.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\nRequirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\nRequirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\nRequirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\nRequirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\nRequirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (14.0.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\nRequirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.9->chromadb) (0.45.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\nRequirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\nRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai==0.8.4) (1.67.0)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (1.48.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.4) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.4) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.4) (4.9)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.22.3)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\nRequirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\nRequirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph==0.3.30) (1.33)\nRequirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph==0.3.30) (1.9.1)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\nRequirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.4.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\nRequirement already satisfied: opentelemetry-proto==1.27.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\nRequirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\nRequirement already satisfied: opentelemetry-instrumentation==0.48b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\nRequirement already satisfied: opentelemetry-util-http==0.48b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\nRequirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (75.1.0)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\nRequirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\nRequirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\nRequirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai==0.8.4) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai==0.8.4) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai==0.8.4) (0.4.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.30.2)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\nRequirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\nRequirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai==0.8.4) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai==0.8.4) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai==0.8.4) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai==0.8.4) (3.2.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\nRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph==0.3.30) (3.0.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.8.4) (0.6.1)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.2->langchain-community) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nUsing cached google_generativeai-0.8.4-py3-none-any.whl (175 kB)\nUsing cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\nInstalling collected packages: google-ai-generativelanguage, google-generativeai\nSuccessfully installed google-ai-generativelanguage-0.6.15 google-generativeai-0.8.4\n✅ Libraries installed (including langgraph>=0.3.30)\n✅ Libraries installed (0.8.4 / 0.6.15 pair)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# [2] Core Library Imports & Version Check\n---\nImports essential libraries for parsing, RAG, LangGraph flow, and Gemini interaction.  \nAlso verifies library versions to ensure compatibility across environments.","metadata":{}},{"cell_type":"code","source":"# Import core libraries\n# core libraries\nimport importlib.metadata as im\nimport google.generativeai as genai\nimport langchain, langgraph\n\n# critical modules\nfrom langchain_google_genai import (\n    ChatGoogleGenerativeAI,\n    GoogleGenerativeAIEmbeddings\n)\nfrom langchain.vectorstores import Chroma\nfrom langchain.chains import RetrievalQA\nfrom langgraph.graph import StateGraph, END\nfrom typing import TypedDict\n# API\nfrom kaggle_secrets import UserSecretsClient\n# utilities\n#from pypdf import PdfReader\n#from pdf2image import convert_from_path\n#import pytesseract\nimport pandas as pd, os, re, textwrap, json\nimport logging\nimport PyPDF2\n\n\nlogging.basicConfig(level=logging.INFO, format=\"%(message)s\")\nlogger = logging.getLogger(__name__)\n\nprint(\"Versions\")\nfor pkg in (\n    \"google-generativeai\",\n    \"google-ai-generativelanguage\",\n    \"langchain\",\n    \"langchain-google-genai\",\n    \"langgraph\",\n    \"langchain-core\",\n):\n    print(\"   •\", pkg, \":\", im.version(pkg))\nprint(\"✅ Versions checked\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:44:24.068310Z","iopub.execute_input":"2025-04-19T15:44:24.068578Z","iopub.status.idle":"2025-04-19T15:44:26.392379Z","shell.execute_reply.started":"2025-04-19T15:44:24.068554Z","shell.execute_reply":"2025-04-19T15:44:26.391453Z"}},"outputs":[{"name":"stdout","text":"Versions\n   • google-generativeai : 0.8.4\n   • google-ai-generativelanguage : 0.6.15\n   • langchain : 0.3.23\n   • langchain-google-genai : 2.0.10\n   • langgraph : 0.3.30\n   • langchain-core : 0.3.54\n✅ Versions checked\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# [3] API Configuration & Gemini Initialization\n---\nSets up the Gemini Flash 2.5 API for text generation and embedding.  \nCredentials are securely handled via Kaggle’s environment.  \nAlso configures model endpoints used in resume rewriting and RAG chains.","metadata":{}},{"cell_type":"code","source":"# Set up API key\nsecrets = UserSecretsClient()\nAPI_KEY = secrets.get_secret(\"JRAA_Gemini_API\")\n\ngenai.configure(api_key=API_KEY)\nos.environ[\"GOOGLE_API_KEY\"] = API_KEY          # optional, but handy for other libs\n\nprint(\"✅ API key configured\")\n\nllm_chat  = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")   # LangChain wrapper\nllm_flash = genai.GenerativeModel(\"gemini-1.5-flash\")          # Direct SDK handle\n\nprint(\"✅ Gemini 1.5 Flash ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:44:26.393292Z","iopub.execute_input":"2025-04-19T15:44:26.393724Z","iopub.status.idle":"2025-04-19T15:44:26.590060Z","shell.execute_reply.started":"2025-04-19T15:44:26.393694Z","shell.execute_reply":"2025-04-19T15:44:26.589136Z"}},"outputs":[{"name":"stdout","text":"✅ API key configured\n✅ Gemini 1.5 Flash ready\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# [4] PDF Text Extraction\n---\nExtracts resume content from PDF files using `PyPDF2`.  \nOCR fallback via Tesseract was planned but not used in the final version due to parsing reliability.","metadata":{}},{"cell_type":"code","source":"def extract_text_from_pdf(path: str) -> str:\n    \"\"\"\n    Extracts all text from each PDF page using PyPDF2.\n    Does not perform any OCR fallback.\n    \"\"\"\n    reader = PyPDF2.PdfReader(path)\n    return \"\\n\".join(page.extract_text() or \"\" for page in reader.pages)\nprint(\"✅ PyPDF2.PdfReader\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:44:26.591896Z","iopub.execute_input":"2025-04-19T15:44:26.592762Z","iopub.status.idle":"2025-04-19T15:44:26.598487Z","shell.execute_reply.started":"2025-04-19T15:44:26.592733Z","shell.execute_reply":"2025-04-19T15:44:26.597522Z"}},"outputs":[{"name":"stdout","text":"✅ PyPDF2.PdfReader\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# [5] UX Insight Embeddings & RAG Setup\n---\nLoads bilingual UX survey data and converts it into embeddings using Gemini.  \nThe insights are stored in ChromaDB and used to generate personalized job advice via Retrieval-Augmented Generation (RAG).","metadata":{}},{"cell_type":"code","source":"# Load UX Survey + Seed Advice\ndf = pd.read_json(\"/kaggle/input/ux-survey-career-japan/ux_survey.json\")\nux_insights = df.dropna(subset=[\"Please describe specific obstacles\"])\\\n                .apply(lambda r: f\"{r['Please describe specific obstacles']} \"\n                                f\"(Visa: {r['Current Visa Status']}, JP: {r['Your Japanese Language Proficiency Level']})\",\n                       axis=1).tolist()\n\n\n# Define seeds\njob_advice_seeds = [\n    \"In Japan, it's important to include your JLPT level and photo on your resume.\",\n    \"Recruiters expect short and formal 自己PR statements. Don't write more than 300 words.\",\n    \"N4 is acceptable for entry-level or technical roles, but more companies prefer N3 or above.\",\n    \"If you want to work in tech, learn some basic business Japanese (keigo expressions like お世話になります).\",\n    \"Try mixing Japanese and English job boards to maximize exposure.\",\n    \"Many companies in Japan follow fixed hiring cycles (like April or October). Timing your application can improve response rates.\",\n    \"Japanese interviews often include questions like 'Why Japan?' or 'What do you know about our company?' Be prepared to answer these.\",\n    \"Avoid vague or overly casual expressions in 自己PR. Japanese recruiters value humility and clear structure.\"\n] + ux_insights\n# Setup RAG chain\nemb = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n\njob_advice_retriever = Chroma.from_texts(\n    job_advice_seeds,\n    embedding=emb\n).as_retriever(k=3)\n\nrag_chain = RetrievalQA.from_chain_type(\n    llm=llm_chat,\n    retriever=job_advice_retriever,\n    return_source_documents=False\n)\n\nprint(\"✅ RAG chain ready with\", len(job_advice_seeds), \"snippets\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:44:26.599527Z","iopub.execute_input":"2025-04-19T15:44:26.599854Z","iopub.status.idle":"2025-04-19T15:44:27.927918Z","shell.execute_reply.started":"2025-04-19T15:44:26.599832Z","shell.execute_reply":"2025-04-19T15:44:27.926993Z"}},"outputs":[{"name":"stdout","text":"✅ RAG chain ready with 24 snippets\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# [6] Tool Functions","metadata":{}},{"cell_type":"markdown","source":"## [6.1] CV Parsing & JSON Extraction\n---\nUses Gemini to extract structured fields from uploaded Japanese résumés.  \nReturns a JSON object containing name, education, skills, certifications, 自己PR, and more.","metadata":{}},{"cell_type":"code","source":"def parse_cv_node(cv_path: str) -> dict:\n    print(\"[Outside loop] Running parse_cv_node\")\n    raw_cv = extract_text_from_pdf(cv_path)\n    prompt = (\n        \"Extract the following fields and return ONLY valid JSON:\\n\"\n        \"- name, dob, nationality, address, phone, email,\\n\"\n        \"- education (list of strings), work_experience, certifications, skills,\\n\"\n        \"- self_pr, motivation\\n\\n\"\n        + raw_cv\n    )\n    out = llm_flash.generate_content(prompt).text.strip()\n    m = re.search(r\"\\{.*\\}\", out, re.S)\n    if not m:\n        raise ValueError(f\"JSON parse failed:\\n{out}\")\n    parsed = json.loads(m.group(0))\n    print(\"✅ Parsed CV JSON:\")\n    return {\"raw_cv\": raw_cv, \"parsed_cv\": parsed}\n\nCV_PATH = \"/kaggle/input/sample/Daniel-Thompson-Resume.pdf\"\nparsed = parse_cv_node(CV_PATH)\nraw_cv, parsed_cv = parsed[\"raw_cv\"], parsed[\"parsed_cv\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:44:27.928701Z","iopub.execute_input":"2025-04-19T15:44:27.928927Z","iopub.status.idle":"2025-04-19T15:44:32.906158Z","shell.execute_reply.started":"2025-04-19T15:44:27.928907Z","shell.execute_reply":"2025-04-19T15:44:32.905265Z"}},"outputs":[{"name":"stdout","text":"[Outside loop] Running parse_cv_node\n✅ Parsed CV JSON:\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## [6.2.1] Tailor CV Node — Rewrite 自己PR & 志望動機\n---\nGenerates formal Japanese self-promotion and motivation statements tailored to the target company.  \nUses few-shot prompting with structured resume input and optional company info.","metadata":{}},{"cell_type":"code","source":"def tailor_cv_node(state: dict) -> dict:\n    import re\n\n    # Utility: count Japanese (non-ASCII) characters\n    def count_japanese_chars(s: str) -> int:\n        return sum(1 for ch in s if ord(ch) > 127)\n\n    company      = state[\"company\"]\n    raw          = state[\"raw_cv\"]\n    cv           = state[\"parsed_cv\"]\n\n    # Retrieve company info (fallback to LLM if not found)\n    company_info = retrieve_company_info(company)\n    if not company_info:\n        company_info = llm_flash.generate_content(\n            f\"Provide the mission, values, and recent highlights of {company}.\"\n        ).text.strip()\n\n    # Build the rewrite prompt using structured rules\n    prompt = (\n        # No emojis, no placeholders\n        \"Output starting with ENGLISH short reply for example Here's your rewrite resume. or Rewrite version to align with {company}\\n\"\n        \"Please output ONLY the resume content—no emojis, no “🤖” markers, no text in brackets. \"\n        \"Use the actual names from the extracted fields. If some name is missing, substitute a generic term.\\n\\n\"\n        # Formatting rules\n        \"- Use Japanese résumé conventions (履歴書), formal tone.\\n\"\n        \"- Append English translations in parentheses immediately after each Japanese line.\\n\"\n        \"- List jobs in reverse‑chronological order with consistent bullet length.\\n\"\n        \"- 自己PRは200～300文字以内で作成してください。\\n\"\n        \"- 志望動機は200～300文字以内で作成してください。\\n\"\n        \"- Incorporate 貴社 into the 自己PR section to demonstrate respect.\\n\\n\"\n        # Rewrite instruction\n        f\"Rewrite the entire CV to align with {company}:\\n\\n\"\n        f\"氏名: {cv['name']}\\n\"\n        f\"生年月日・国籍: {cv['dob']}／{cv['nationality']}\\n\"\n        f\"住所・連絡先: {cv['address']}／{cv['phone']}／{cv['email']}\\n\\n\"\n        \"学歴:\\n\" + \"\\n\".join(f\"  * {e}\" for e in cv[\"education\"]) + \"\\n\\n\"\n        \"職務経歴:\\n\" + \"\\n\".join(f\"  * {e}\" for e in cv[\"work_experience\"]) + \"\\n\\n\"\n        \"資格:\\n\" + \"\\n\".join(f\"  * {c}\" for c in cv[\"certifications\"]) + \"\\n\\n\"\n        \"スキル:\\n\" + \"\\n\".join(f\"  * {s}\" for s in cv[\"skills\"]) + \"\\n\\n\"\n        f\"自己PR: {cv['self_pr']}\\n\\n\"\n        f\"志望動機: {cv['motivation']}\\n\\n\"\n        # Company context\n        f\"※Company Info for {company}:\\n{company_info}\\n\"\n    )\n\n    # Generate initial rewrite\n    result = llm_flash.generate_content(prompt).text.strip()\n\n    # Enforce 自己PR length (200–300 Japanese characters)\n    match = re.search(r\"自己PR:\\s*(.+?)(?:\\n\\n|$)\", result, re.S)\n    if match:\n        jiko_pr = match.group(1).strip()\n        length  = count_japanese_chars(jiko_pr)\n        if length < 200 or length > 300:\n            followup = f\"Your 自己PR is {length}文字です。200～300文字になるよう調整してください。\"\n            result   = llm_flash.generate_content(prompt + \"\\n\\n\" + followup).text.strip()\n\n    return {**state, \"result\": result}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:44:32.906984Z","iopub.execute_input":"2025-04-19T15:44:32.907218Z","iopub.status.idle":"2025-04-19T15:44:32.917459Z","shell.execute_reply.started":"2025-04-19T15:44:32.907189Z","shell.execute_reply":"2025-04-19T15:44:32.916440Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## [6.2.2] Company Info Retrieval\n---\nFetches mission, values, and recent highlights of the target company using Gemini.  \nThis context is embedded into the CV rewriting prompt to improve personalization.","metadata":{}},{"cell_type":"code","source":"def retrieve_company_info(company: str) -> str:\n    #print(\"✅ retrieve_company_info\")\n    # Simulate a database or web fetch #this can change into RAG in the future develop\n    dummy_info = {\n        \"Capcom\": \"Capcom is a global video game developer known for Resident Evil and Monster Hunter.\",\n        \"Rakuten\": \"Rakuten is a Japanese e-commerce and internet services company with a global presence.\",\n        \"Toyota\": \"Toyota is a leading automotive company focused on innovation and sustainability.\"\n    }\n    #print(\"✅ Exit retrieve_company_info\")\n    return dummy_info.get(company, f\"{company} is a company in Japan. More details are not available.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:44:32.918485Z","iopub.execute_input":"2025-04-19T15:44:32.919158Z","iopub.status.idle":"2025-04-19T15:44:32.937057Z","shell.execute_reply.started":"2025-04-19T15:44:32.919118Z","shell.execute_reply":"2025-04-19T15:44:32.936257Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## [6.3] UX Advice Node — RAG-Based Career Support\n---\nGenerates personalized job advice using RAG.  \nCombines user certifications (JLPT, TOEIC) with embedded UX survey insights to recommend actionable next steps for working in Japan.","metadata":{}},{"cell_type":"code","source":"def job_advice_node(state: dict) -> dict:\n    \"\"\"\n    Use RAG to answer the user's own query (e.g. “give me job advice”),\n    grounded in their profile and the UX survey insights.\n    Enforce a consistent, numbered format but let the user dictate the task.\n    \"\"\"\n    cv      = state[\"parsed_cv\"]\n    query   = state[\"query\"]  # e.g. \"give me job advice\"\n    \n    # Extract the user's real certification data\n    jlpt    = next((c for c in cv[\"certifications\"] if \"日本語能力試験\" in c),\n                   \"日本語能力試験 N? 未取得\")\n    toeic   = next((c for c in cv[\"certifications\"] if \"TOEIC\" in c),\n                   \"TOEIC 未取得\")\n    skills  = \", \".join(cv[\"skills\"])\n    \n    # Fold in UX survey bullet points\n    ux_ctx  = \"\\n\".join(f\"- {tip}\" for tip in ux_insights)\n    \n    # Guard‑rails on formatting, independent of the user task\n    formatting = (\n        \"Output your answer as a numbered list with at least 3 items (unless the user's request \"\n        \"specifies otherwise). For each item:\\n\"\n        \"  1. Bold the title of the item.\\n\"\n        \"  2. On the next line, prefix “- Advice:” for a brief action.\\n\"\n        \"  3. On a following line, prefix “- Resources:” for links or tools (if applicable).\\n\"\n        \"All output must be in English; Japanese words are allowed only with translations in parentheses.\\n\\n\"\n    )\n    \n    # Build the dynamic prompt\n    prompt = (\n        formatting +\n        \"Candidate profile:\\n\"\n        f\"- {jlpt}\\n\"\n        f\"- {toeic}\\n\"\n        f\"- Skills: {skills}\\n\"\n        f\"- QA roles: {len(cv['work_experience'])}\\n\\n\"\n        \"UX survey insights (reported barriers):\\n\"\n        f\"{ux_ctx}\\n\\n\"\n        \"User request:\\n\"\n        f\"{query}\\n\\n\"\n        \"Please answer the user's request above, following the formatting rules.\"\n    )\n    \n    # Invoke RAG (use invoke to avoid deprecation)\n    raw_output = rag_chain.invoke({\"query\": prompt})\n    \n    # Extract the string if we got a dict\n    advice_text = raw_output.get(\"result\", raw_output) if isinstance(raw_output, dict) else raw_output\n    \n    # Ensure real line breaks\n    advice = advice_text.replace(\"\\\\n\", \"\\n\")\n    \n    return {**state, \"result\": advice}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:44:32.937890Z","iopub.execute_input":"2025-04-19T15:44:32.938184Z","iopub.status.idle":"2025-04-19T15:44:32.954223Z","shell.execute_reply.started":"2025-04-19T15:44:32.938161Z","shell.execute_reply":"2025-04-19T15:44:32.953172Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## [6.4] Alternative Job Suggestion Node\n---\nSuggests 5 alternative job paths based on the user’s parsed resume profile.  \nUses Gemini to generate role suggestions, stores them temporarily in a Chroma vector index, and retrieves the most relevant ones.  \nSupports structured, RAG-style output with Japanese terms and translations.","metadata":{}},{"cell_type":"code","source":"def recommend_alt_jobs_node(state: dict) -> dict:\n    \"\"\"\n    Suggest 5 alternative job roles in Japan from the Resume below,\n    and format each item as:\n      1. **<Job Title in English>** (<Japanese title>):\n         - Transition Advice: …\n         - Recommended Courses/Skills: …\n    Permit Japanese words only with translations in ().\n    \"\"\"\n\n    raw_cv = state[\"raw_cv\"]\n\n    # Build a structured prompt\n    prompt = (\n        # Formatting guard rails\n        \"Output exactly 5 numbered items. For each:\\n\"\n        \"  1. Bold the English job title and put the Japanese title in parentheses.\\n\"\n        \"  2. On the next line, prefix “- Transition Advice:” and give a 1‑sentence tip.\\n\"\n        \"  3. On the following line, prefix “- Recommended Courses/Skills:” and list any study suggestions.\\n\"\n        \"All output must be in English. Japanese words are allowed only with an English translation in parentheses.\\n\\n\"\n        # What to base it on\n        \"Suggest alternative roles based on this résumé:\\n\\n\"\n        f\"{raw_cv}\\n\"\n    )\n\n\n    # Call the LLM\n    text = llm_flash.generate_content(prompt).text\n\n    # Split into individual non-empty lines\n    suggestions = [line for line in text.splitlines() if line.strip()]\n\n    # Join back into a clean multi-line string\n    result_text = \"\\n\".join(suggestions)\n\n    return {**state, \"result\": result_text}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:44:32.957004Z","iopub.execute_input":"2025-04-19T15:44:32.957605Z","iopub.status.idle":"2025-04-19T15:44:32.976248Z","shell.execute_reply.started":"2025-04-19T15:44:32.957576Z","shell.execute_reply":"2025-04-19T15:44:32.975320Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def build_alt_job_store(profile: str):\n\n    \"\"\"\n    Returns a Chroma retriever seeded with alternative‑job snippets,\n    ready to query using the candidate's raw CV text.\n    \"\"\"\n    # alt_job_snippets is a list of strings you prepared earlier\n    return Chroma.from_texts(\n        alt_job_snippets,      # your 4–5 prewritten alternative‑job doc strings\n        embedding=emb\n    ).as_retriever(k=5)\n\n    \n    #print(\"🧭 Enter build_alt_job_store\")\n    prompt = (\n        \"Suggest 5 alternative job roles in Japan from the data you get from the Resume below.\"\n        \"Return each suggestion as one sentence and also include Advice about transition into a new position.\"\n        \"If you have some recommended course or skill set, recommend it.\"\n        \"PLEASE NOTE THAT ANSWER MUST BE IN ENGLISH, You can use Japanese for important WORD but you have to add () and write translation inside after that word\\n\\n\" + profile\n    )\n    suggestions = llm_flash.generate_content(prompt).text.splitlines()\n\n    # ✅ In-memory only — avoids persistence errors\n    return Chroma.from_texts(suggestions, embedding=emb).as_retriever(k=2)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:44:32.977348Z","iopub.execute_input":"2025-04-19T15:44:32.977597Z","iopub.status.idle":"2025-04-19T15:44:32.997311Z","shell.execute_reply.started":"2025-04-19T15:44:32.977578Z","shell.execute_reply":"2025-04-19T15:44:32.996328Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# [7] LangGraph Agent Flow & Routing\n---\nDefines the LangGraph architecture used to control chatbot flow.  \nRoutes user input dynamically to the correct node based on intent (e.g., rewrite resume, get advice, explore new jobs).  \nEach node reads and updates shared state using a dictionary-based agent state model.","metadata":{}},{"cell_type":"code","source":"# Shared State\nclass AgentState(TypedDict):\n    query: str\n    result: str\n    company: str\n    parsed_cv: str  # Optional but useful in CV use case\n    raw_cv: str\n\n# Routing Logic\ndef route(state: AgentState) -> str:\n    #print(\"📊 Full State Contents:\")\n    \n    if \"raw_cv\" not in state:\n        state[\"raw_cv\"] = raw_cv\n        \n    for key, value in state.items():\n        preview = str(value)[:100].replace(\"\\n\", \" \")\n        #print(f\"🔑 {key}: {preview}...\")\n\n    query = state.get(\"query\", \"\").lower()\n    if any(keyword in query for keyword in [\"rewrite\", \"志望動機\", \"resume\", \"自己pr\"]):\n        #print(\"➡️ Routing to: tailor_cv_node\")\n        return \"tailor_cv_node\"\n        \n    elif any(keyword in query for keyword in [\"job advice\", \"how to find job\", \"how can i get a job\", \"career advice\", \"how to apply\", \"job in japan\"]):\n        #print(\"➡️ Routing to: job_advice_node\")\n        return \"job_advice_node\"\n\n    elif any(keyword in query for keyword in [\"alternative job\", \"job suit\", \"recommend job\", \"what job\", \"career\", \"仕事\", \"職種\"]):\n        #print(\"➡️ Routing to: recommend_alt_jobs\")\n        return \"recommend_alt_jobs\"\n\n    print(\"🛑 No match — ending flow\")\n    return \"default_fallback\"\n\n\n# Build the Graph\nbuilder = StateGraph(AgentState)\n\n# Only add actual processing nodes\nbuilder.add_node(\"tailor_cv_node\", tailor_cv_node)\nbuilder.add_node(\"job_advice_node\", job_advice_node)\nbuilder.add_node(\"recommend_alt_jobs\", recommend_alt_jobs_node)\n\nbuilder.set_entry_point(\"start_router\")  # pick a new internal router node\n\n# Register a dummy node to represent router\ndef router_entry_node(state: AgentState) -> AgentState:\n    #print(\"🚦 Initial router node\")\n    return state\n\nbuilder.add_node(\"start_router\", router_entry_node)\n\n# Then update your conditional routing:\nbuilder.add_conditional_edges(\"start_router\", route, {\n    \"tailor_cv_node\": \"tailor_cv_node\",\n    \"job_advice_node\": \"job_advice_node\",\n    \"recommend_alt_jobs\": \"recommend_alt_jobs\",\n    \"default_fallback\": END\n})\n\n# Optional: loop back to router if needed\n# builder.add_edge(\"tailor_cv_node\", \"router\")\n# builder.add_edge(\"ux_advice\", \"router\")\n# builder.add_edge(\"recommend_alt_jobs\", \"router\")\n\n# Compile\nmulti_agent = builder.compile()\nprint(\"✅ Builder Compiled\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:44:32.998350Z","iopub.execute_input":"2025-04-19T15:44:32.998723Z","iopub.status.idle":"2025-04-19T15:44:33.027910Z","shell.execute_reply.started":"2025-04-19T15:44:32.998701Z","shell.execute_reply":"2025-04-19T15:44:33.027022Z"}},"outputs":[{"name":"stdout","text":"✅ Builder Compiled\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# [8] Chatbot Simulation Loop\n---\nRuns an interactive chatbot loop using the LangGraph agent.  \nSupports natural user queries like “rewrite my resume” or “give me job advice,” routing them to the correct tool.  \nIdeal for testing resume rewrites, advice generation, and job recommendations in real time.","metadata":{}},{"cell_type":"code","source":"def chatbot_simulator():\n    print(\"🤖 JobBridge‑AI: Welcome to JobBridge‑AI!\")\n    print(\"💬 Type: “rewrite my resume”, “give me job advice”, or “suggest alternative jobs”\")\n    print(\"🛑 Quit with q / quit / exit\\n\")\n\n    while True:\n        user_input = input(\"🧠 You: \").strip()\n        print(f\"📝 User Input: {user_input}\")\n        if user_input.lower() in {\"q\", \"quit\", \"exit\"}:\n            print(\"👋 Ending Session\")\n            break\n\n        state = {\n            \"raw_cv\":    raw_cv,\n            \"parsed_cv\": parsed_cv,\n            \"query\":     user_input,\n            \"company\":   \"\"\n        }\n        if \"rewrite\" in user_input.lower():\n            state[\"company\"] = input(\"🏢 Which company? \").strip()\n\n        #print(\"🌀 Running agent flow…\")\n        response = multi_agent.invoke(state)\n\n        # Extract and clean the advice string\n        advice = response.get(\"result\", \"⚠️ No result returned.\")\n        advice = advice.replace(\"\\\\n\", \"\\n\")\n\n        # Print it out—using the same variable name!\n        print(\n            f\"\\n🤖 JobBridge‑AI:\\n\"\n            f\"{advice}\\n\"\n            f\"{'-'*40}\\n\"\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:44:33.028912Z","iopub.execute_input":"2025-04-19T15:44:33.029455Z","iopub.status.idle":"2025-04-19T15:44:33.050397Z","shell.execute_reply.started":"2025-04-19T15:44:33.029423Z","shell.execute_reply":"2025-04-19T15:44:33.049583Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Execute Program","metadata":{}},{"cell_type":"code","source":"chatbot_simulator()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:44:33.051307Z","iopub.execute_input":"2025-04-19T15:44:33.051559Z","iopub.status.idle":"2025-04-19T15:47:15.521064Z","shell.execute_reply.started":"2025-04-19T15:44:33.051541Z","shell.execute_reply":"2025-04-19T15:47:15.520251Z"}},"outputs":[{"name":"stdout","text":"🤖 JobBridge‑AI: Welcome to JobBridge‑AI!\n💬 Type: “rewrite my resume”, “give me job advice”, or “suggest alternative jobs”\n🛑 Quit with q / quit / exit\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"🧠 You:  rewrite my resume\n"},{"name":"stdout","text":"📝 User Input: rewrite my resume\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"🏢 Which company?  Sony Group Corporation\n"},{"name":"stdout","text":"\n🤖 JobBridge‑AI:\n氏名: Daniel Thompson (Name: Daniel Thompson)\n生年月日・国籍: 1992年5月14日／ニュージーランド国籍 (Date of Birth and Nationality: May 14, 1992 / New Zealand)\n住所・連絡先: 〒150-0002 東京都渋谷区渋谷2-15-1 渋谷クロスタワー24階／080-1234-5678／daniel.t@example.com (Address and Contact Information:  Shibuya Crosta Tower 24F, 2-15-1 Shibuya, Shibuya-ku, Tokyo 150-0002 / 080-1234-5678 / daniel.t@example.com)\n\n学歴:\nオークランド大学 メディア・コミュニケーション学部 卒業 (Auckland University, Graduated from the Department of Media and Communication)\n\n職務経歴:\n渋谷日本語センター  (Shibuya Japanese Language Center)\n2019年1月～現在 (January 2019 - Present)\n・日本語教育における業務に従事 (Engaged in Japanese language education)\n\n\n株式会社 ScriptWorks  広告代理店 (ScriptWorks Inc., Advertising Agency)\n2010年4月～2018年12月 (April 2010 - December 2018)\n・脚本、コピーライティング業務に従事 (Engaged in scriptwriting and copywriting)\n・多文化チームとの協働によるプロジェクト多数実施 (Executed numerous projects in collaboration with multicultural teams)\n\n\n資格:\nTESOL（英語教育資格） (TESOL (English Language Teaching Qualification))\n日本語能力試験 N2 合格 (Japanese Language Proficiency Test N2 Pass)\n\nスキル:\n日本語（ビジネス会話レベル） (Japanese (Business Conversational Level))\n英語（ネイティブ） (English (Native))\nスクリプトライティング・コピーライティング (Scriptwriting and Copywriting)\nAdobe Creative Cloud（Photoshop, Premiere Pro） (Adobe Creative Cloud (Photoshop, Premiere Pro))\nGoogle Workspace・Notion・Slack (Google Workspace, Notion, Slack)\n\n\n自己PR:\nニュージーランド出身のメディア専門家として、日本で培った経験とスキルを活かし、貴社のグローバルな事業展開に貢献したいと考えております。広告代理店での脚本・コピーライティング経験を通じて培った表現力と、日本語教育における経験を通じて培った異文化コミュニケーション能力は、貴社の多様なサービスを世界に向けて発信する上で大きな強みになると確信しております。  特に、多文化チームでの協働経験から得た柔軟性と問題解決能力は、貴社のグローバルなチームにおいても有効に活用できると考えています。  貴社の革新的な技術と文化への理解を深め、より質の高いコンテンツ制作に貢献したいと願っております。(As a media professional from New Zealand, I believe my experience and skills cultivated in Japan will contribute to Sony Group Corporation’s global business development. My experience in scriptwriting and copywriting at an advertising agency, combined with my experience in Japanese language education, has equipped me with strong expression skills and intercultural communication abilities, which I am confident will be great assets in disseminating your diverse services to the world.  In particular, the flexibility and problem-solving skills I gained from collaborating in multicultural teams will be effectively utilized within Sony Group Corporation’s global team. I aspire to deepen my understanding of your company’s innovative technology and culture, and contribute to the creation of higher-quality content.)\n\n\n志望動機:\nソニーグループ株式会社は、革新的な技術とエンターテインメントを通して世界中の人々に感動を与え続ける、グローバルリーディングカンパニーです。  私は、その企業理念に深く共感し、貴社の一員として貢献したいと考えております。  ニュージーランドの広告代理店と日本の教育現場での経験を通じて培ってきた、多様な文化への理解と、正確かつ魅力的な表現力は、貴社のグローバルなコミュニケーション戦略に大きな価値をもたらすと確信しております。  特に、日本語と英語のバイリンガル能力を活かし、グローバルなコミュニケーションの円滑化に貢献したいと考えています。  貴社のミッションに共感し、その実現に貢献できることを心から願っております。(Sony Group Corporation is a global leading company that continues to inspire people around the world through its innovative technology and entertainment. I deeply resonate with this corporate philosophy and wish to contribute as a member of your company.  The understanding of diverse cultures and ability to create accurate and compelling content, cultivated through my experiences at a New Zealand advertising agency and in Japanese education, will undoubtedly bring significant value to your global communication strategy. In particular, I wish to leverage my bilingual abilities in Japanese and English to contribute to smoother global communication. I am deeply committed to your mission and sincerely hope to contribute to its realization.)\n----------------------------------------\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"🧠 You:  rewrite my resume\n"},{"name":"stdout","text":"📝 User Input: rewrite my resume\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"🏢 Which company?  楽天グループ株式会社\n"},{"name":"stdout","text":"\n🤖 JobBridge‑AI:\n氏名：Daniel Thompson (Name: Daniel Thompson)\n生年月日・国籍：1992年5月14日／ニュージーランド国籍 (Date of Birth and Nationality: May 14, 1992 / New Zealand)\n住所・連絡先：〒150-0002 東京都渋谷区渋谷2-15-1 渋谷クロスタワー24階／080-1234-5678／daniel.t@example.com (Address and Contact Information: 24F, Shibuya Cross Tower, 2-15-1 Shibuya, Shibuya-ku, Tokyo 150-0002 / 080-1234-5678 / daniel.t@example.com)\n\n学歴：\nオークランド大学 メディア・コミュニケーション学部 卒業 (Auckland University, Graduated from the Department of Media and Communication)\n\n職務経歴：\n渋谷日本語センター (Shibuya Japanese Language Center)  2019年1月～現在 (January 2019 - Present)\n　 ・日本語教育補助講師として勤務 (Worked as an Assistant Language Teacher)\n株式会社 ScriptWorks (ScriptWorks Inc.) ニュージーランド 2010年4月～2018年12月 (New Zealand, April 2010 - December 2018)\n　 ・広告代理店でコピーライター、スクリプトライターとして勤務 (Worked as a copywriter and scriptwriter at an advertising agency)\n　　・多様なクライアントのための広告コピー、ウェブサイトコンテンツ、動画スクリプトを制作 (Created advertising copy, website content, and video scripts for diverse clients.)\n　　・多文化チームと協力して、効果的なマーケティング戦略を立案・実行 (Planned and executed effective marketing strategies in collaboration with multicultural teams.)\n\n\n資格：\nTESOL（英語教育資格）(TESOL (English Teaching Qualification))\n日本語能力試験N2合格 (Japanese Language Proficiency Test N2)\n\nスキル：\n日本語（ビジネス会話レベル）(Japanese (Business Conversational Level))\n英語（ネイティブ）(English (Native))\nスクリプトライティング・コピーライティング (Scriptwriting and Copywriting)\nAdobe Creative Cloud（Photoshop, Premiere Pro）(Adobe Creative Cloud (Photoshop, Premiere Pro))\nGoogle Workspace・Notion・Slack (Google Workspace, Notion, Slack)\n\n自己PR：\nニュージーランド出身のメディア専門家として、広告代理店での経験と日本の教育現場での経験を活かし、貴社のグローバルな展開に貢献したいと考えております。前職の広告代理店では、多文化チームと連携し、創造的なコンテンツ制作に携わってきました。脚本・コピーライティングスキルに加え、Adobe Creative Cloud等のツールを活用した制作にも精通しております。また、渋谷日本語センターでのALT経験を通じて培った、日本文化への深い理解と、日本語運用能力（N2）を活かし、貴社のサービスを正確かつ効果的にローカライズすることで、世界中のユーザーへより魅力的なコンテンツを提供できると確信しております。楽天グループ株式会社の多様なサービスを支える一員として、貢献できることを楽しみにしています。(As a media professional from New Zealand, I aim to leverage my experience in advertising agencies and Japanese educational settings to contribute to Rakuten Group's global expansion. In my previous role at an advertising agency, I collaborated with multicultural teams on creative content creation.  In addition to my scriptwriting and copywriting skills, I am proficient in using tools such as Adobe Creative Cloud.  Furthermore, my experience as an ALT at Shibuya Japanese Language Center has cultivated a deep understanding of Japanese culture and Japanese language proficiency (N2). I am confident that I can utilize these skills to accurately and effectively localize Rakuten's services, providing more engaging content to users worldwide. I look forward to contributing as a member of the team supporting Rakuten Group's diverse services.)\n\n\n志望動機：\n楽天グループ株式会社のグローバルな展開と、多様なサービスに強い魅力を感じ、志望いたしました。日本の教育現場での経験を通して培った日本文化への理解と、ニュージーランドの広告代理店での経験を通して培ったクリエイティブな表現力、そして英語ネイティブとしてのスキルを活かし、貴社のグローバルな事業展開に貢献したいと考えております。特に、多言語対応におけるローカライズの重要性を感じており、私の日本語能力（N2）と英語ネイティブのスキルを活かし、世界中のお客様に、貴社のサービスをより親しみやすく、自然な形で届けることができるよう尽力したいと考えています。(I am applying for a position at Rakuten Group because I am strongly attracted to its global expansion and diverse services. I want to contribute to Rakuten's global business by leveraging my understanding of Japanese culture cultivated through experience in Japanese education, creative expression skills honed at a New Zealand advertising agency, and my skills as a native English speaker. In particular, I recognize the importance of localization in multilingual support and want to devote myself to making Rakuten's services more approachable and natural for global customers by utilizing my Japanese language proficiency (N2) and native English skills.)\n----------------------------------------\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"🧠 You:  give me job advice\n"},{"name":"stdout","text":"📝 User Input: give me job advice\n\n🤖 JobBridge‑AI:\n1. **Target Foreign Companies**\n- Advice: Focus your job search on foreign companies operating in Japan.  They are often more open to candidates with lower Japanese proficiency and may be more willing to conduct interviews in English.\n- Resources: Websites like Indeed Japan, LinkedIn, and Glassdoor can be filtered to show foreign companies.\n\n\n2. **Network Strategically**\n- Advice: Leverage your existing network and actively build new connections within your field. Attend industry events (even online ones) and connect with people on LinkedIn. Networking can lead to unadvertised opportunities.\n- Resources: LinkedIn, Meetup.com, industry-specific online forums.\n\n\n3. **Highlight Transferable Skills**\n- Advice: Emphasize the skills you possess that are transferable to QA roles, even if your Japanese language skills aren't at N1 level. Your experience, creative skills (Adobe Creative Cloud proficiency), and familiarity with Google Workspace and Notion are valuable assets.  Tailor your resume and cover letter to showcase how these skills align with specific job requirements.\n- Resources:  Resume and cover letter templates online, career counseling services.\n\n\n4. **Improve Japanese Gradually**\n- Advice: While focusing on securing a position, continue to improve your Japanese language skills.  Even incremental improvements will increase your opportunities over time.  N2 is a strong foundation, but further study will be beneficial.\n- Resources: Language exchange apps (HelloTalk, Tandem), online Japanese courses (Memrise, Duolingo, iTalki), local Japanese language schools.\n\n\n5. **Address the \"Teaching\" Bias**\n- Advice:  Proactively address the common assumption that foreign nationals in Japan are only suited for teaching roles. In your cover letter and interviews, clearly state your interest in QA and your relevant experience.  Showcase your portfolio to demonstrate your skills and passion.\n- Resources:  Examples of strong cover letters and interview preparation resources can be found online.\n----------------------------------------\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"🧠 You:  suggest alternative jobs\n"},{"name":"stdout","text":"📝 User Input: suggest alternative jobs\n\n🤖 JobBridge‑AI:\n1. **Copywriter** (コピーライター)\n- Transition Advice: Leverage your experience in script and copywriting at ScriptWorks to highlight your creative writing abilities.\n- Recommended Courses/Skills:  Advanced copywriting techniques, SEO writing,  content marketing strategies.\n2. **Localization Specialist** (ローカライゼーションスペシャリスト)\n- Transition Advice:  Emphasize your native English fluency, Japanese language proficiency (N2), and experience working in multicultural teams.\n- Recommended Courses/Skills:  Translation (English-Japanese, Japanese-English), localization management, software localization, cultural sensitivity training.\n3. **Content Creator** (コンテンツクリエーター)\n- Transition Advice: Showcase your experience creating content in both English and Japanese, highlighting your adaptability and cross-cultural understanding.\n- Recommended Courses/Skills: Content strategy, social media marketing, video editing, graphic design basics (if applicable).\n4. **Technical Writer** (テクニカルライター)\n- Transition Advice: Combine your copywriting skills with your understanding of technology and software (Google Workspace, Notion, Adobe Creative Cloud) to demonstrate your ability to explain complex information clearly.\n- Recommended Courses/Skills: Technical writing principles, API documentation, user manual creation, software testing basics.\n5. **Marketing Communications Specialist** (マーケティングコミュニケーションズスペシャリスト)\n- Transition Advice:  Highlight your experience in advertising, copywriting, and working with diverse teams to demonstrate your ability to develop and execute effective marketing strategies.\n- Recommended Courses/Skills: Digital marketing, marketing analytics, public relations, campaign management.\n----------------------------------------\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"🧠 You:  Quit\n"},{"name":"stdout","text":"📝 User Input: Quit\n👋 Ending Session\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## -------------------------------------------\n","metadata":{}}]}